{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3a421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # disable warning and info message\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb09c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the fourth GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25813812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ready\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "\n",
    "# Download the data.\n",
    "DOWNLOAD_URL = 'http://mattmahoney.net/dc/'\n",
    "DATA_FOLDER = \"data\"\n",
    "FILE_NAME = \"text8.zip\"\n",
    "EXPECTED_BYTES = 31344016\n",
    "\n",
    "def make_dir(path):\n",
    "    \"\"\" Create a directory if there isn't one already. \"\"\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "    \n",
    "def download(file_name, expected_bytes):\n",
    "    \"\"\" Download the dataset text8 if it's not already downloaded \"\"\"\n",
    "    local_file_path = os.path.join(DATA_FOLDER, file_name)\n",
    "    if os.path.exists(local_file_path):\n",
    "        print(\"Dataset ready\")\n",
    "        return local_file_path\n",
    "    file_name, _ = urllib.request.urlretrieve(os.path.join(DOWNLOAD_URL, file_name), local_file_path)\n",
    "    file_stat = os.stat(local_file_path)\n",
    "    if file_stat.st_size == expected_bytes:\n",
    "        print('Successfully downloaded the file', file_name)\n",
    "    else:\n",
    "        raise Exception(\n",
    "              'File ' + file_name +\n",
    "              ' might be corrupted. You should try downloading it with a browser.')\n",
    "    return local_file_path    \n",
    "    \n",
    "make_dir(DATA_FOLDER)\n",
    "file_path = download(FILE_NAME, EXPECTED_BYTES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83f456df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size 17005207\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# Read the data into a list of strings.\n",
    "def read_data(file_path):\n",
    "    \"\"\" Read data into a list of tokens \"\"\"\n",
    "    with zipfile.ZipFile(file_path) as f:\n",
    "        # tf.compat.as_str() converts the input into string\n",
    "        data = tf.compat.as_str(f.read(f.namelist()[0])).split()\n",
    "    return data\n",
    "\n",
    "vocabulary = read_data(file_path)\n",
    "print('Data size', len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28bcbc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anarchism', 'originated', 'as', 'a', 'term']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f2a1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "# Build the dictionary and replace rare words with UNK token.\n",
    "def build_dataset(words, n_words):\n",
    "    \"\"\" Create two dictionaries and count of occuring words\n",
    "        - word_to_id: map of words to their codes\n",
    "        - id_to_word: maps codes to words (inverse word_to_id)\n",
    "        - count: map of words to count of occurrences\n",
    "    \"\"\"\n",
    "    # map unknown words to -1\n",
    "    count = [['UNK', -1]]\n",
    "    # count of occurences for words in vocabulary\n",
    "    count.extend(collections.Counter(words).most_common(n_words - 1)) \n",
    "    word_to_id = dict() # (word, id)\n",
    "    # record word id\n",
    "    for word, _ in count:\n",
    "        word_to_id[word] = len(word_to_id)\n",
    "    id_to_word = dict(zip(word_to_id.values(), word_to_id.keys())) # (id, word)\n",
    "    return word_to_id, id_to_word, count\n",
    "\n",
    "def convert_words_to_id(words, dictionary, count):\n",
    "    \"\"\" Replace each word in the dataset with its index in the dictionary \"\"\"\n",
    "    data_w2id = []\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        # return 0 if word is not in dictionary\n",
    "        index = dictionary.get(word, 0)\n",
    "        if index == 0:\n",
    "            unk_count += 1\n",
    "        data_w2id.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    return data_w2id, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aa7a16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Filling 4 global variables:\n",
    "# data_w2id - list of codes (integers from 0 to vocabulary_size-1).\n",
    "              This is the original text but words are replaced by their codes\n",
    "# count - map of words(strings) to count of occurrences\n",
    "# word_to_id - map of words(strings) to their codes(integers)\n",
    "# id_to_word - maps codes(integers) to words(strings)\n",
    "\"\"\"\n",
    "\n",
    "vocabulary_size = 50000\n",
    "word_to_id, id_to_word, count = build_dataset(vocabulary, vocabulary_size)\n",
    "data_w2id, count = convert_words_to_id(vocabulary, word_to_id, count)\n",
    "del vocabulary  # reduce memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b91339b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words (+UNK) [['UNK', 418391], ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764)]\n",
      "Sample data: [5234, 3081, 12, 6, 195, 2, 3134, 46, 59, 156]\n",
      "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against']\n"
     ]
    }
   ],
   "source": [
    "print('Most common words (+UNK)', count[:5])\n",
    "print('Sample data: {}'.format(data_w2id[:10]))\n",
    "print([id_to_word[i] for i in data_w2id[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2745903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function\n",
    "def generate_sample(center_words, context_window_size):\n",
    "    \"\"\" Form training pairs according to the skip-gram model. \"\"\"\n",
    "    for idx, center in enumerate(center_words):\n",
    "        context = random.randint(1, context_window_size)\n",
    "        # get a random target before the center word\n",
    "        for target in center_words[max(0, idx - context) : idx]:\n",
    "            yield center, target\n",
    "        # get a random target after the center word\n",
    "        for target in center_words[idx + 1 : idx + context + 1]:\n",
    "            yield center, target\n",
    "\n",
    "def batch_generator(data, skip_window, batch_size):\n",
    "    \"\"\" Group a numeric stream into batches and yield them as Numpy arrays. \"\"\"\n",
    "    single_gen = generate_sample(data, skip_window)\n",
    "    while True:\n",
    "        center_batch = np.zeros(batch_size, dtype=np.int32)\n",
    "        target_batch = np.zeros([batch_size, 1], dtype=np.int32)\n",
    "        for idx in range(batch_size):\n",
    "            center_batch[idx], target_batch[idx] = next(single_gen)\n",
    "        yield center_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66558548",
   "metadata": {},
   "outputs": [],
   "source": [
    "## some training settings\n",
    "training_steps = 80000\n",
    "skip_step = 2000\n",
    "\n",
    "## some hyperparameters\n",
    "batch_size = 512\n",
    "embed_size = 512\n",
    "num_sampled = 256\n",
    "learning_rate = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3976770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "# embedding matrix - hidden layer\n",
    "class embedding_lookup(Layer):\n",
    "    def __init__(self):\n",
    "        super(embedding_lookup, self).__init__()\n",
    "        embedding_init = tf.keras.initializers.GlorotUniform()\n",
    "        self.embedding_matrix = self.add_weight(name=\"embedding_matrix\",\n",
    "                                                trainable=True,\n",
    "                                                shape=[vocabulary_size, embed_size],\n",
    "                                                initializer=embedding_init)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        center_words = inputs\n",
    "        embedding = tf.nn.embedding_lookup(self.embedding_matrix,\n",
    "                                           center_words, \n",
    "                                           name='embedding')\n",
    "        return embedding\n",
    "\n",
    "# context matrix - prediction layer\n",
    "class nce_loss(Layer):\n",
    "    def __init__(self):\n",
    "        super(nce_loss, self).__init__()\n",
    "        nce_w_init = tf.keras.initializers.TruncatedNormal(stddev=1.0/(embed_size ** 0.5))\n",
    "        self.nce_weight = self.add_weight(name='nce_weight',\n",
    "                                          trainable=True,\n",
    "                                          shape=[vocabulary_size, embed_size],\n",
    "                                          initializer=nce_w_init)\n",
    "        self.nce_bias = self.add_weight(name='nce_bias',\n",
    "                                        trainable=True,\n",
    "                                        shape=[vocabulary_size],\n",
    "                                        initializer=tf.keras.initializers.Zeros)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        embedding, target_words = inputs[0], inputs[1]\n",
    "        loss = tf.reduce_mean(tf.nn.nce_loss(weights=self.nce_weight, \n",
    "                                             biases=self.nce_bias, \n",
    "                                             labels=target_words, \n",
    "                                             inputs=embedding, \n",
    "                                             num_sampled=num_sampled, \n",
    "                                             num_classes=vocabulary_size),\n",
    "                                             name='loss')\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e3b7379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "\n",
    "center_words = Input(shape=(), name='center_words', dtype='int32')\n",
    "target_words = Input(shape=(1), name='target_words', dtype='int32')\n",
    "\n",
    "embedding = embedding_lookup()(center_words)\n",
    "loss = nce_loss()((embedding, target_words))\n",
    "\n",
    "word2vec = Model(name='word2vec',\n",
    "                 inputs=[center_words, target_words],\n",
    "                 outputs=[loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "127d4d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"word2vec\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "center_words (InputLayer)       [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_lookup (embedding_loo (None, 512)          25600000    center_words[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "target_words (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "nce_loss (nce_loss)             ()                   25650000    embedding_lookup[0][0]           \n",
      "                                                                 target_words[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 51,250,000\n",
      "Trainable params: 51,250,000\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "word2vec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dcba627",
   "metadata": {},
   "outputs": [],
   "source": [
    "## geneartor for `tf.data.Dataset`\n",
    "def gen():\n",
    "    \"\"\" Return a python generator that generates batches. \"\"\"\n",
    "    yield from batch_generator(data_w2id, 2, batch_size)\n",
    "\n",
    "    \n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(gen, \n",
    "                                         (tf.int32, tf.int32),\n",
    "                                         (tf.TensorShape([batch_size]), tf.TensorShape([batch_size, 1])))\\\n",
    "                         .repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9e37407",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.1,nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f86eca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(center_words, target_words):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = word2vec([center_words, target_words])\n",
    "    gradients = tape.gradient(loss, word2vec.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, word2vec.trainable_variables))\n",
    "\n",
    "    train_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86a7a2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2000, Loss: 174.90\n",
      "Step 4000, Loss: 31.22\n",
      "Step 6000, Loss: 15.68\n",
      "Step 8000, Loss: 10.73\n",
      "Step 10000, Loss: 9.61\n",
      "Step 12000, Loss: 8.72\n",
      "Step 14000, Loss: 8.15\n",
      "Step 16000, Loss: 7.43\n",
      "Step 18000, Loss: 7.14\n",
      "Step 20000, Loss: 6.97\n",
      "Step 22000, Loss: 6.89\n",
      "Step 24000, Loss: 6.73\n",
      "Step 26000, Loss: 6.57\n",
      "Step 28000, Loss: 6.44\n",
      "Step 30000, Loss: 6.42\n",
      "Step 32000, Loss: 6.39\n",
      "Step 34000, Loss: 6.26\n",
      "Step 36000, Loss: 6.26\n",
      "Step 38000, Loss: 6.14\n",
      "Step 40000, Loss: 6.12\n",
      "Step 42000, Loss: 6.10\n",
      "Step 44000, Loss: 5.95\n",
      "Step 46000, Loss: 5.94\n",
      "Step 48000, Loss: 5.99\n",
      "Step 50000, Loss: 5.91\n",
      "Step 52000, Loss: 5.87\n",
      "Step 54000, Loss: 5.95\n",
      "Step 56000, Loss: 5.89\n",
      "Step 58000, Loss: 5.85\n",
      "Step 60000, Loss: 5.92\n",
      "Step 62000, Loss: 5.82\n",
      "Step 64000, Loss: 5.82\n",
      "Step 66000, Loss: 5.88\n",
      "Step 68000, Loss: 5.81\n",
      "Step 70000, Loss: 5.75\n",
      "Step 72000, Loss: 5.92\n",
      "Step 74000, Loss: 5.78\n",
      "Step 76000, Loss: 5.45\n",
      "Step 78000, Loss: 5.60\n",
      "Step 80000, Loss: 5.70\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "for step, (center_words, target_words) in enumerate(dataset):\n",
    "    if step == training_steps:\n",
    "        break\n",
    "    train_step(center_words, target_words)\n",
    "\n",
    "    if ((step+1) % skip_step) == 0:\n",
    "        template = 'Step {:0}, Loss: {:.2f}'\n",
    "        x.append(step+1)\n",
    "        y.append(train_loss.result())\n",
    "        print (template.format(step+1, train_loss.result()))\n",
    "        train_loss.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67f2dc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5503828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embedding matrxi from model weights. > word2vec.weights[0]\n",
    "embedding_matrix = word2vec.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15daba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_labels(low_dim_embs, labels):\n",
    "    assert low_dim_embs.shape[0] >= len(labels), 'More labels than embeddings'\n",
    "    plt.figure(figsize=(18, 18), dpi=150)  # in inches\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = low_dim_embs[i, :]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(\n",
    "            label,\n",
    "            xy=(x, y),\n",
    "            xytext=(5, 2),\n",
    "            textcoords='offset points',\n",
    "            ha='right',\n",
    "            va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d1f606b",
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U32'), dtype('<U32')) -> dtype('<U32')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_149015/1133360204.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplot_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfinal_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlow_dim_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mplot_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mid_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplot_with_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow_dim_embs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \"\"\"\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0mdegrees_of_freedom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return self._tsne(P, degrees_of_freedom, n_samples,\n\u001b[0m\u001b[1;32m    842\u001b[0m                           \u001b[0mX_embedded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m                           \u001b[0mneighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneighbors_nn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_tsne\u001b[0;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;31m# higher learning rate controlled via the early exaggeration parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0mP\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_exaggeration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m         params, kl_divergence, it = _gradient_descent(obj_func, params,\n\u001b[0m\u001b[1;32m    883\u001b[0m                                                       **opt_args)\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_gradient_descent\u001b[0;34m(objective, p0, it, n_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_gain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mgains\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mupdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U32'), dtype('<U32')) -> dtype('<U32')"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000, method='exact', learning_rate='auto')\n",
    "plot_only = 400\n",
    "final_embeddings = embedding_matrix.numpy()\n",
    "low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only, :])\n",
    "labels = [id_to_word[i] for i in range(plot_only)]\n",
    "plot_with_labels(low_dim_embs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f58545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d418724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handy method for calculating the similarity between 2 word\n",
    "def cos_sim(word1, word2):\n",
    "    id1 = word_to_id[word1]\n",
    "    id2 = word_to_id[word2]\n",
    "    \n",
    "    vec1 = embedding_matrix[id1].numpy()\n",
    "    vec2 = embedding_matrix[id2].numpy()\n",
    "\n",
    "    return np.dot(vec1, vec2) / (LA.norm(vec1) * LA.norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0824ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim('cat', 'dog'), cos_sim('man', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb45f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_nearest(word, k):\n",
    "    vec = embedding_matrix[word_to_id[word]]\n",
    "    \n",
    "    # calaulate cosine similarity  of `vec` and all other vocabularies\n",
    "    dot = np.dot(embedding_matrix.numpy(), vec)\n",
    "    embedding_norm = LA.norm(embedding_matrix.numpy(), axis=-1)\n",
    "    vec_norm = LA.norm(vec)\n",
    "    norm_product = embedding_norm * vec_norm\n",
    "    cos_sim = dot / norm_product\n",
    "    \n",
    "    # print out top k nearest words\n",
    "    indices = np.argsort(cos_sim)[::-1][:k]\n",
    "    print('---top {} nearest words of {}---'.format(k, word))\n",
    "    for idx in indices:\n",
    "        print(id_to_word[idx])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc24445",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_nearest('england', 5)\n",
    "top_k_nearest('rock', 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
