{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3d88d34",
   "metadata": {},
   "source": [
    "# Lab14-2 GAN\n",
    "110065508 李丞恩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7f37daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_COL = 16\n",
    "SAMPLE_ROW = 16\n",
    "SAMPLE_NUM = SAMPLE_COL * SAMPLE_ROW\n",
    "\n",
    "IMG_H = 64\n",
    "IMG_W = 64\n",
    "IMG_C = 3\n",
    "IMG_SHAPE = (IMG_H, IMG_W, IMG_C)\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "Z_DIM = 128\n",
    "BZ = (BATCH_SIZE, Z_DIM)\n",
    "BUF = 65536\n",
    "\n",
    "DC_LR = 2.5e-04\n",
    "DC_EPOCH = 256\n",
    "\n",
    "W_LR = 2.0e-04\n",
    "W_EPOCH = 256\n",
    "WClipLo = -0.01\n",
    "WClipHi = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "389d8fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-20 00:40:07.464500: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import imageio\n",
    "import moviepy.editor as mpy\n",
    "import IPython.display as display\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import random\n",
    "import re\n",
    "from pprint import pprint\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras import utils, datasets, layers, models\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2415600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # disable warnings and info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2d30d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-20 00:40:08.423131: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-20 00:40:08.453800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-20 00:40:08.454274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3060 computeCapability: 8.6\n",
      "coreClock: 1.852GHz coreCount: 28 deviceMemorySize: 11.77GiB deviceMemoryBandwidth: 335.32GiB/s\n",
      "2021-12-20 00:40:08.454296: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-20 00:40:08.456109: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-20 00:40:08.456256: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-20 00:40:08.456979: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-20 00:40:08.457152: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-20 00:40:08.457751: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-12-20 00:40:08.458171: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-12-20 00:40:08.458253: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-20 00:40:08.458346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-20 00:40:08.458897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-20 00:40:08.459341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], \\\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit = 10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "596f6f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"input\") : os.mkdir(\"input\")\n",
    "if not os.path.exists(\"output\") : os.mkdir(\"output\")\n",
    "if not os.path.exists(\"output/gif\") : os.mkdir(\"output/gif\")\n",
    "if not os.path.exists(\"output/imgs_HW\") : os.mkdir(\"output/imgs_HW\")\n",
    "if not os.path.exists(\"output/imgs_not_HW\") : os.mkdir(\"output/imgs_not_HW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e733c6",
   "metadata": {},
   "source": [
    "## 一. 製作CelebA的tfrecord檔"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c75163e",
   "metadata": {},
   "source": [
    "### 1. Write tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5c7e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = pathlib.Path('./input/datalab-lab-14-2')\n",
    "all_image_paths = list(data_root.glob('*'))\n",
    "all_image_paths = [str(path) for path in all_image_paths]\n",
    "all_image_paths = [path for path in all_image_paths if path[-3:] in ('png')]\n",
    "image_count = len(all_image_paths)\n",
    "print('\\ntotal img num:', image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65248e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value): # Returns a bytes_list from a string / byte.\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def to_tfrecord(img):  \n",
    "    feature={\n",
    "        \"image\": _bytes_feature(img)\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "def prepare_tfrecords(dataset_path, tfrecord_file):\n",
    "    with tf.io.TFRecordWriter(tfrecord_file) as out_file:\n",
    "        index = [i for i in range(len(dataset_path))]\n",
    "        for i in range(len(dataset_path)):\n",
    "            img = open(dataset_path[index[i]], 'rb').read() #  Read the images\n",
    "            example = to_tfrecord(img) # write to \n",
    "            out_file.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130bd6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare_tfrecords(all_image_paths, './input/dataset.tfrecord') # 跑過一次就不要再跑了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0f031b",
   "metadata": {},
   "source": [
    "### 2. preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da237d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a description of the features.\n",
    "feature_description = {\n",
    "    'image': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto): # # Parse the input `tf.Example` proto using the dictionary above.\n",
    "    feature_dict = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    img = tf.io.decode_png(feature_dict['image'], channels=IMG_C)\n",
    "    img = tf.image.resize(img, (IMG_H, IMG_W))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b079188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(tfrecord_file):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95de14a9",
   "metadata": {},
   "source": [
    "### 3. Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36a85e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsTrain = read_dataset('./input/dataset.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94040cb0",
   "metadata": {},
   "source": [
    "## 二. 設計GAN的架構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bb7942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GAN(img_shape, z_dim):\n",
    "    # x-shape\n",
    "    xh, xw, xc = img_shape\n",
    "    # z-shape\n",
    "    zh = xh // 4\n",
    "    zw = xw // 4\n",
    "        \n",
    "    # return Generator and Discriminator\n",
    "    return keras.Sequential([ # Generator\n",
    "        keras.layers.Dense(units  =  1024, input_shape = (z_dim,)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Dense(units  =  zh * zw << 8), # zh * zw * 256\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Reshape(target_shape = (zh, zw, 256)),\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters = 32,\n",
    "            kernel_size = 5,\n",
    "            strides = 2,\n",
    "            padding = \"SAME\"\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters = xc,\n",
    "            kernel_size = 5,\n",
    "            strides = 2,\n",
    "            padding = \"SAME\",\n",
    "            activation = keras.activations.sigmoid\n",
    "        ),\n",
    "    ]), keras.Sequential([ # Discriminator\n",
    "        keras.layers.Conv2D(\n",
    "            filters = 32,\n",
    "            kernel_size = 5,\n",
    "            strides = (2, 2),\n",
    "            padding = \"SAME\",\n",
    "            input_shape = img_shape,\n",
    "        ),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        keras.layers.Conv2D(\n",
    "            filters = 128,\n",
    "            kernel_size = 5,\n",
    "            strides = (2, 2),\n",
    "            padding = \"SAME\"\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(units  =  1024),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        keras.layers.Dense(units  =  1),\n",
    "    ])\n",
    "\n",
    "s = tf.random.normal([SAMPLE_NUM, Z_DIM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2074ca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "IWG, IWD = GAN(IMG_SHAPE, Z_DIM)\n",
    "optimizer_g = keras.optimizers.Adam(W_LR, beta_1=0, beta_2=0.9)\n",
    "optimizer_d = keras.optimizers.Adam(W_LR, beta_1=0, beta_2=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe0901e",
   "metadata": {},
   "source": [
    "## 三. GAN的訓練函數定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27434b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def IWGTrain(c1):\n",
    "    with tf.GradientTape() as tpg:\n",
    "        with tf.GradientTape() as tp_gradientpenalty:\n",
    "            x = c1 # sample x from \\mathbb{P}_r\n",
    "            z = tf.random.normal(BZ) # sample latent variable z form p(z)\n",
    "            epsilon = tf.random.uniform([BATCH_SIZE,1,1,1]) # sample \\epsilon from U[0,1]\n",
    "            \n",
    "            x_tilde = IWG(z, training = True) # \\tilde{x}<-G_\\theta(z)\n",
    "            x_hat = epsilon * x + (1 - epsilon) * x_tilde # do linear combination\n",
    "            \n",
    "            Dwx_tilde = IWD(x, training = True)\n",
    "            Dwx = IWD(x_tilde, training = True)\n",
    "            grad = IMPROVED_WD(x_hat, training = True)\n",
    "            penalty = 10 * tf.math.square(tf.norm(tp_gradientpenalty.gradient(grad, x_tilde), ord='euclidean') - 1)\n",
    "            loss = Dwx_tilde - Dwx + penalty\n",
    "            \n",
    "            ld = tf.reduce_mean(loss)\n",
    "            lg = - tf.reduce_mean(z0)\n",
    "        \n",
    "    gradient_g = tpg.gradient(lg, IWG.trainable_variables)\n",
    "    optimizer_g.apply_gradients(zip(gradient_g, IWG.trainable_variables))\n",
    "    return lg, ld\n",
    "\n",
    "@tf.function\n",
    "def IWDTrain(c1):\n",
    "    with tf.GradientTape() as tpg:\n",
    "        with tf.GradientTape() as tp_gradientpenalty:\n",
    "            x = c1 # sample x from \\mathbb{P}_r\n",
    "            z = tf.random.normal(BZ) # sample latent variable z form p(z)\n",
    "            epsilon = tf.random.uniform([BATCH_SIZE,1,1,1]) # sample \\epsilon from U[0,1]\n",
    "            \n",
    "            x_tilde = IWG(z, training = True) # \\tilde{x}<-G_\\theta(z)\n",
    "            x_hat = epsilon * x + (1 - epsilon) * x_tilde # do linear combination\n",
    "            \n",
    "            Dwx_tilde = IWD(x, training = True)\n",
    "            Dwx = IWD(x_tilde, training = True)\n",
    "            grad = IMPROVED_WD(x_hat, training = True)\n",
    "            penalty = 10 * tf.math.square(tf.norm(tp_gradientpenalty.gradient(grad, x_tilde), ord='euclidean') - 1)\n",
    "            loss = Dwx_tilde - Dwx + penalty\n",
    "            \n",
    "            ld = tf.reduce_mean(loss)\n",
    "            lg = - tf.reduce_mean(z0)\n",
    "        \n",
    "    gradient_d = tpd.gradient(ld, IWD.trainable_variables)\n",
    "    optimizer_d.apply_gradients(zip(gradient_d, IWD.trainable_variables)) # No weight clipping in improved WGAN!\n",
    "    return lg, ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ca9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio of training step D:G = 5:1\n",
    "WTrain = (\n",
    "    IWDTrain,\n",
    "    IWDTrain,\n",
    "    IWDTrain,\n",
    "    IWDTrain,\n",
    "    IWDTrain,\n",
    "    IWGTrain\n",
    ")\n",
    "\n",
    "WCritic = len(WTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e288b29",
   "metadata": {},
   "source": [
    "## 四. 訓練過程視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd936e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function\n",
    "def utPuzzle(imgs, row, col, path=None):\n",
    "    h, w, c = imgs[0].shape\n",
    "    out = np.zeros((h * row, w * col, c), np.uint8)\n",
    "    for n, img in enumerate(imgs):\n",
    "        j, i = divmod(n, col)\n",
    "        out[j * h : (j + 1) * h, i * w : (i + 1) * w, :] = img\n",
    "    if path is not None : imageio.imwrite(path, out)\n",
    "    return out\n",
    "  \n",
    "def utMakeGif(imgs, fname, duration):\n",
    "    n = float(len(imgs)) / duration\n",
    "    clip = mpy.VideoClip(lambda t : imgs[int(n * t)], duration = duration)\n",
    "    clip.write_gif(fname, fps = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d509e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wlg = [None] * W_EPOCH #record loss of g for each epoch\n",
    "wld = [None] * W_EPOCH #record loss of d for each epoch\n",
    "wsp = [None] * W_EPOCH #record sample images for each epoch\n",
    "\n",
    "rsTrain = float(BATCH_SIZE) / float(image_count)\n",
    "ctr = 0\n",
    "for ep in tqdm(range(W_EPOCH)):\n",
    "    lgt = 0.0\n",
    "    ldt = 0.0\n",
    "    for c1 in dsTrain:\n",
    "        lg, ld = WTrain[ctr](c1)\n",
    "        ctr += 1\n",
    "        lgt += lg.numpy()\n",
    "        ldt += ld.numpy()\n",
    "        if ctr == WCritic : ctr = 0\n",
    "    wlg[ep] = lgt * rsTrain\n",
    "    wld[ep] = ldt * rsTrain\n",
    "    \n",
    "    out = IWG(s, training = False)\n",
    "    img = utPuzzle(\n",
    "        (out * 255.0).numpy().astype(np.uint8),\n",
    "        SAMPLE_COL,\n",
    "        SAMPLE_ROW,\n",
    "        \"./output/imgs_HW/iw_%04d.png\" % ep\n",
    "    )\n",
    "    wsp[ep] = img\n",
    "    if (ep+1) % 32 == 0:\n",
    "        \n",
    "        plt.imshow(img[..., 0], cmap = \"gray\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Epoch %d\" % ep)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5ded9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "utMakeGif(np.array(wsp), \"./output/gif/improved_wgan_celebA_110065508.gif\", duration = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20065950",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(W_EPOCH), wld, color = \"blue\", label = \"Discriminator Loss\")\n",
    "plt.plot(range(W_EPOCH), wlg, color = \"red\", label = \"Generator Loss\")\n",
    "plt.legend(loc = \"upper right\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Improved WGAN Training Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
