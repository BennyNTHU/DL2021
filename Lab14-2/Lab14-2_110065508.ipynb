{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3d88d34",
   "metadata": {},
   "source": [
    "# Lab14-2 GAN\n",
    "110065508 李丞恩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7f37daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_COL = 8\n",
    "SAMPLE_ROW = 8\n",
    "SAMPLE_NUM = SAMPLE_COL * SAMPLE_ROW\n",
    "\n",
    "IMG_H = 64\n",
    "IMG_W = 64\n",
    "IMG_C = 3\n",
    "IMG_SHAPE = (IMG_H, IMG_W, IMG_C)\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "Z_DIM = 128\n",
    "BZ = (BATCH_SIZE, Z_DIM)\n",
    "BUFFER_SIZE = 100\n",
    "\n",
    "DC_LR = 2.5e-04\n",
    "DC_EPOCH = 256\n",
    "\n",
    "W_LR = 2.0e-04\n",
    "W_EPOCH = 256\n",
    "WClipLo = -0.01\n",
    "WClipHi = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "389d8fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-20 01:51:09.620698: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import imageio\n",
    "import moviepy.editor as mpy\n",
    "import IPython.display as display\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import random\n",
    "import re\n",
    "from pprint import pprint\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras import utils, datasets, layers, models\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2415600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # disable warnings and info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2d30d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-20 01:51:10.618222: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-20 01:51:10.650658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-20 01:51:10.651160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3060 computeCapability: 8.6\n",
      "coreClock: 1.852GHz coreCount: 28 deviceMemorySize: 11.77GiB deviceMemoryBandwidth: 335.32GiB/s\n",
      "2021-12-20 01:51:10.651182: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-20 01:51:10.654159: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-20 01:51:10.654199: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-20 01:51:10.654734: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-20 01:51:10.654861: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-20 01:51:10.655399: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-12-20 01:51:10.655793: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-12-20 01:51:10.655868: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-20 01:51:10.655938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-20 01:51:10.656447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-20 01:51:10.656891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], \\\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit = 10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "596f6f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"input\") : os.mkdir(\"input\")\n",
    "if not os.path.exists(\"output\") : os.mkdir(\"output\")\n",
    "if not os.path.exists(\"output/gif\") : os.mkdir(\"output/gif\")\n",
    "if not os.path.exists(\"output/imgs_HW\") : os.mkdir(\"output/imgs_HW\")\n",
    "if not os.path.exists(\"output/imgs_not_HW\") : os.mkdir(\"output/imgs_not_HW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e733c6",
   "metadata": {},
   "source": [
    "## 一. 製作CelebA的tfrecord檔"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c75163e",
   "metadata": {},
   "source": [
    "### 1. Write tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc5c7e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total img num: 202599\n"
     ]
    }
   ],
   "source": [
    "data_root = pathlib.Path('./input/datalab-lab-14-2')\n",
    "all_image_paths = list(data_root.glob('*'))\n",
    "all_image_paths = [str(path) for path in all_image_paths]\n",
    "all_image_paths = [path for path in all_image_paths if path[-3:] in ('png')]\n",
    "image_count = len(all_image_paths)\n",
    "print('\\ntotal img num:', image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65248e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value): # Returns a bytes_list from a string / byte.\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def to_tfrecord(img):  \n",
    "    feature={\n",
    "        \"image\": _bytes_feature(img)\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "def prepare_tfrecords(dataset_path, tfrecord_file):\n",
    "    with tf.io.TFRecordWriter(tfrecord_file) as out_file:\n",
    "        index = [i for i in range(len(dataset_path))]\n",
    "        for i in range(len(dataset_path)):\n",
    "            img = open(dataset_path[index[i]], 'rb').read() #  Read the images\n",
    "            example = to_tfrecord(img) # write to \n",
    "            out_file.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "130bd6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare_tfrecords(all_image_paths, './input/dataset.tfrecord') # 跑過一次就不要再跑了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0f031b",
   "metadata": {},
   "source": [
    "### 2. preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da237d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a description of the features.\n",
    "feature_description = {\n",
    "    'image': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto): # # Parse the input `tf.Example` proto using the dictionary above.\n",
    "    feature_dict = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    img = tf.io.decode_png(feature_dict['image'], channels=IMG_C)\n",
    "    img = tf.image.resize(img, (IMG_H, IMG_W))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b079188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(tfrecord_file):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    # 一定加drop_remainder=True，否則最後一個batch數量會不夠,導致訓練時出錯！\n",
    "    dataset = dataset.shuffle(BUFFER_SIZE) \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95de14a9",
   "metadata": {},
   "source": [
    "### 3. Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d36a85e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-20 01:51:11.367213: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-20 01:51:11.367694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-20 01:51:11.368217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3060 computeCapability: 8.6\n",
      "coreClock: 1.852GHz coreCount: 28 deviceMemorySize: 11.77GiB deviceMemoryBandwidth: 335.32GiB/s\n",
      "2021-12-20 01:51:11.368312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-20 01:51:11.368790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-20 01:51:11.369236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-12-20 01:51:11.369282: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-20 01:51:11.669595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-20 01:51:11.669622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-12-20 01:51:11.669626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-12-20 01:51:11.669769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-20 01:51:11.670295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-20 01:51:11.670762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-20 01:51:11.671186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10000 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "dsTrain = read_dataset('./input/dataset.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c86dcff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset shapes: (200, 64, 64, 3), types: tf.float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94040cb0",
   "metadata": {},
   "source": [
    "## 二. 設計GAN的架構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75bb7942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GAN(img_shape, z_dim):\n",
    "    # x-shape\n",
    "    xh, xw, xc = img_shape\n",
    "    # z-shape\n",
    "    zh = xh // 4\n",
    "    zw = xw // 4\n",
    "        \n",
    "    # return Generator and Discriminator\n",
    "    return keras.Sequential([ # Generator\n",
    "        keras.layers.Dense(units  =  1024, input_shape = (z_dim,)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Dense(units  =  zh * zw << 8), # zh * zw * 256\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Reshape(target_shape = (zh, zw, 256)),\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters = 32,\n",
    "            kernel_size = 5,\n",
    "            strides = 2,\n",
    "            padding = \"SAME\"\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters = xc,\n",
    "            kernel_size = 5,\n",
    "            strides = 2,\n",
    "            padding = \"SAME\",\n",
    "            activation = keras.activations.sigmoid\n",
    "        ),\n",
    "    ]), keras.Sequential([ # Discriminator\n",
    "        keras.layers.Conv2D(\n",
    "            filters = 32,\n",
    "            kernel_size = 5,\n",
    "            strides = (2, 2),\n",
    "            padding = \"SAME\",\n",
    "            input_shape = img_shape,\n",
    "        ),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        keras.layers.Conv2D(\n",
    "            filters = 128,\n",
    "            kernel_size = 5,\n",
    "            strides = (2, 2),\n",
    "            padding = \"SAME\"\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(units  =  1024),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        keras.layers.Dense(units  =  1),\n",
    "    ])\n",
    "\n",
    "s = tf.random.normal([SAMPLE_NUM, Z_DIM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2074ca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "IWG, IWD = GAN(IMG_SHAPE, Z_DIM)\n",
    "optimizer_g = keras.optimizers.Adam(W_LR, beta_1=0, beta_2=0.9)\n",
    "optimizer_d = keras.optimizers.Adam(W_LR, beta_1=0, beta_2=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe0901e",
   "metadata": {},
   "source": [
    "## 三. GAN的訓練函數定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27434b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def IWGTrain(c1):\n",
    "    z = tf.random.normal(BZ) # sample latent variable z form p(z), I don't know why but just keep it out\n",
    "    with tf.GradientTape() as tpg:\n",
    "        with tf.GradientTape() as tp_gradientpenalty:\n",
    "            x = c1 # sample x from \\mathbb{P}_r\n",
    "            epsilon = np.random.uniform(0, 1) # sample \\epsilon from U[0,1]\n",
    "            \n",
    "            x_tilde = IWG(z, training = True) # \\tilde{x}<-G_\\theta(z)\n",
    "            x_hat = tf.math.scalar_mul(epsilon, x) + tf.math.scalar_mul((1 - epsilon), x_tilde)\n",
    "            \n",
    "            Dwx_tilde = IWD(x_tilde, training = True)\n",
    "            Dwx = IWD(x, training = True)\n",
    "            grad = IWD(x_hat, training = True)\n",
    "            penalty = 10 * tf.math.square(tf.norm(tp_gradientpenalty.gradient(grad, x_tilde), ord='euclidean') - 1)\n",
    "            loss = Dwx_tilde - Dwx + penalty\n",
    "            \n",
    "            ld = tf.reduce_mean(loss)\n",
    "            lg = - tf.reduce_mean(Dwx_tilde)\n",
    "        \n",
    "    gradient_g = tpg.gradient(lg, IWG.trainable_variables)\n",
    "    optimizer_g.apply_gradients(zip(gradient_g, IWG.trainable_variables))\n",
    "    return lg, ld\n",
    "\n",
    "@tf.function\n",
    "def IWDTrain(c1):\n",
    "    z = tf.random.normal(BZ) # sample latent variable z form p(z), I don't know why but just keep it out\n",
    "    with tf.GradientTape() as tpg:\n",
    "        with tf.GradientTape() as tp_gradientpenalty:\n",
    "            x = c1 # sample x from \\mathbb{P}_r\n",
    "            epsilon = np.random.uniform(0, 1) # sample \\epsilon from U[0,1]\n",
    "            \n",
    "            x_tilde = IWG(z, training = True) # \\tilde{x}<-G_\\theta(z)\n",
    "            x_hat = tf.math.scalar_mul(epsilon, x) + tf.math.scalar_mul((1 - epsilon), x_tilde)\n",
    "            \n",
    "            Dwx_tilde = IWD(x_tilde, training = True)\n",
    "            Dwx = IWD(x, training = True)\n",
    "            grad = IWD(x_hat, training = True)\n",
    "            penalty = 10 * tf.math.square(tf.norm(tp_gradientpenalty.gradient(grad, x_tilde), ord='euclidean') - 1)\n",
    "            loss = Dwx_tilde - Dwx + penalty\n",
    "            \n",
    "            ld = tf.reduce_mean(loss)\n",
    "            lg = - tf.reduce_mean(Dwx_tilde)\n",
    "        \n",
    "    gradient_g = tpg.gradient(lg, IWG.trainable_variables)\n",
    "    optimizer_g.apply_gradients(zip(gradient_g, IWG.trainable_variables))\n",
    "    return lg, ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8ca9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio of training step D:G = 5:1\n",
    "WTrain = (\n",
    "    IWDTrain,\n",
    "    IWDTrain,\n",
    "    IWDTrain,\n",
    "    IWDTrain,\n",
    "    IWDTrain,\n",
    "    IWGTrain\n",
    ")\n",
    "\n",
    "WCritic = len(WTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e288b29",
   "metadata": {},
   "source": [
    "## 四. 訓練過程視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd936e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function\n",
    "def utPuzzle(imgs, row, col, path=None):\n",
    "    h, w, c = imgs[0].shape\n",
    "    out = np.zeros((h * row, w * col, c), np.uint8)\n",
    "    for n, img in enumerate(imgs):\n",
    "        j, i = divmod(n, col)\n",
    "        out[j * h : (j + 1) * h, i * w : (i + 1) * w, :] = img\n",
    "    if path is not None : imageio.imwrite(path, out)\n",
    "    return out\n",
    "  \n",
    "def utMakeGif(imgs, fname, duration):\n",
    "    n = float(len(imgs)) / duration\n",
    "    clip = mpy.VideoClip(lambda t : imgs[int(n * t)], duration = duration)\n",
    "    clip.write_gif(fname, fps = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d509e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9074bb2622644efcbe350a18dd70daf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-20 01:51:11.938522: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-20 01:51:11.956280: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2592000000 Hz\n",
      "2021-12-20 01:51:15.212651: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-20 01:51:15.624463: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-20 01:51:15.624502: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2021-12-20 01:51:15.624599: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-20 01:51:16.011445: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8100\n",
      "2021-12-20 01:51:16.519798: E tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-12-20 01:51:16.519824: W tensorflow/stream_executor/gpu/asm_compiler.cc:56] Couldn't invoke ptxas --version\n",
      "2021-12-20 01:51:16.520347: E tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-12-20 01:51:16.520405: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    }
   ],
   "source": [
    "wlg = [None] * W_EPOCH #record loss of g for each epoch\n",
    "wld = [None] * W_EPOCH #record loss of d for each epoch\n",
    "wsp = [None] * W_EPOCH #record sample images for each epoch\n",
    "\n",
    "rsTrain = float(BATCH_SIZE) / float(image_count)\n",
    "ctr = 0\n",
    "for ep in tqdm(range(W_EPOCH)):\n",
    "    lgt = 0.0\n",
    "    ldt = 0.0\n",
    "    for c1 in dsTrain:\n",
    "        lg, ld = WTrain[ctr](c1)\n",
    "        ctr += 1\n",
    "        lgt += lg.numpy()\n",
    "        ldt += ld.numpy()\n",
    "        if ctr == WCritic : ctr = 0\n",
    "    wlg[ep] = lgt * rsTrain\n",
    "    wld[ep] = ldt * rsTrain\n",
    "    \n",
    "    out = IWG(s, training = False)\n",
    "    img = utPuzzle(\n",
    "        (out * 255.0).numpy().astype(np.uint8),\n",
    "        SAMPLE_COL,\n",
    "        SAMPLE_ROW,\n",
    "        \"./output/imgs_HW/iw_%04d.png\" % ep\n",
    "    )\n",
    "    wsp[ep] = img\n",
    "    if (ep+1) % 32 == 0:\n",
    "        \n",
    "        plt.imshow(img[..., 0], cmap = \"gray\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Epoch %d\" % ep)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5ded9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "utMakeGif(np.array(wsp), \"./output/gif/improved_wgan_celebA_110065508.gif\", duration = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20065950",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(W_EPOCH), wld, color = \"blue\", label = \"Discriminator Loss\")\n",
    "plt.plot(range(W_EPOCH), wlg, color = \"red\", label = \"Generator Loss\")\n",
    "plt.legend(loc = \"upper right\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Improved WGAN Training Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
