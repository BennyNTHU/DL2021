{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e23ee7b",
   "metadata": {},
   "source": [
    "# Lab14-2_Assignment\n",
    "\n",
    "## Requirment:\n",
    "\n",
    "- Implement the Improved WGAN.\n",
    "- Train the Improved WGAN on CelebA dataset.\n",
    "- Build dataset that read and resize images to 64 x 64 for training.\n",
    "- Show a gif of generated samples (at least 8 x 8)\n",
    "- Draw the loss curve of discriminator and generator during training process into one image.\n",
    "- Write a brief report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276ae73e",
   "metadata": {},
   "source": [
    "## Report:\n",
    "\n",
    "### 1. reading images\n",
    "- total # = 202599 images\n",
    "\n",
    "### 2. write input images into tf_record\n",
    "- 轉成tf.train.BytesList\n",
    "\n",
    "### 3. resize images to 64 x 64 and normalize them for training\n",
    "\n",
    "### 4. Imporve WGAN\n",
    "- params和lab14-2提供的improve WGAN的參數一樣：\n",
    "- beta_1 = 0, beta_2 = 0.9, lambda = 10\n",
    "\n",
    "### 5. Show a GIF\n",
    "\n",
    "### 6. Draw the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b34a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-22 21:29:01.926231: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import imageio\n",
    "import moviepy.editor as mpy\n",
    "\n",
    "SAMPLE_COL = 8\n",
    "SAMPLE_ROW = 8\n",
    "SAMPLE_NUM = SAMPLE_COL * SAMPLE_ROW\n",
    "\n",
    "IMG_H = 64\n",
    "IMG_W = 64\n",
    "IMG_C = 3\n",
    "IMG_SHAPE = (IMG_H, IMG_W, IMG_C)\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "Z_DIM = 128\n",
    "BZ = (BATCH_SIZE, Z_DIM)\n",
    "BUFFER = 10000\n",
    "\n",
    "# learning rate in IWGAN picture\n",
    "IMPROVED_W_LR = 1e-4\n",
    "IMPROVED_W_EPOCH = 256\n",
    "\n",
    "ITEMS_PER_FILE = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb582a5b",
   "metadata": {},
   "source": [
    "### Error: GPU hanged randomly on some epochs\n",
    "\n",
    "train了很多次，但最多到26 epochs時GPU的利用率就變成0了。\n",
    "\n",
    "https://stackoverflow.com/questions/47272869/tensorflow-stops-training-and-hanged-on-gpu-randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54b7dfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "configproto = tf.compat.v1.ConfigProto() \n",
    "configproto.gpu_options.allow_growth = True\n",
    "configproto.gpu_options.polling_inactive_delay_msecs = 12\n",
    "#sess = tf.compat.v1.Session(config=configproto) \n",
    "#tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "#tf.compat.v1.GPUOptions.polling_inactive_delay_msecs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aefc70eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-22 21:29:03.708738: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-22 21:29:03.761908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-22 21:29:03.762946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3060 computeCapability: 8.6\n",
      "coreClock: 1.852GHz coreCount: 28 deviceMemorySize: 11.77GiB deviceMemoryBandwidth: 335.32GiB/s\n",
      "2021-12-22 21:29:03.762985: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-22 21:29:03.773355: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-22 21:29:03.773422: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-22 21:29:03.778221: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-22 21:29:03.780340: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-22 21:29:03.782693: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-12-22 21:29:03.785180: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-12-22 21:29:03.786026: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-22 21:29:03.786105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-22 21:29:03.786610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-22 21:29:03.787273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-12-22 21:29:03.788474: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-22 21:29:03.789336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-22 21:29:03.789830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3060 computeCapability: 8.6\n",
      "coreClock: 1.852GHz coreCount: 28 deviceMemorySize: 11.77GiB deviceMemoryBandwidth: 335.32GiB/s\n",
      "2021-12-22 21:29:03.789874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-22 21:29:03.790348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-22 21:29:03.790781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-12-22 21:29:03.791028: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-22 21:29:04.329917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-22 21:29:04.329936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-12-22 21:29:04.329940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-12-22 21:29:04.330056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-22 21:29:04.330541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-22 21:29:04.330968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-22 21:29:04.331392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8192 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the specified GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        \n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "        ''' 在8G M1上跑的話要調1024(1G)左右才勉強能跑 '''\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit = 0x2000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4ed164",
   "metadata": {},
   "source": [
    "### 0. Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a97a07b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function\n",
    "def utPuzzle(imgs, row, col, path=None):\n",
    "    h, w, c = imgs[0].shape\n",
    "    out = np.zeros((h * row, w * col, c), np.uint8)\n",
    "    for n, img in enumerate(imgs):\n",
    "        j, i = divmod(n, col)\n",
    "        out[j * h : (j + 1) * h, i * w : (i + 1) * w, :] = img\n",
    "    if path is not None : imageio.imwrite(path, out)\n",
    "    return out\n",
    "  \n",
    "def utMakeGif(imgs, fname, duration):\n",
    "    n = float(len(imgs)) / duration\n",
    "    clip = mpy.VideoClip(lambda t : imgs[int(n * t)], duration = duration)\n",
    "    clip.write_gif(fname, fps = n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f6a7d0",
   "metadata": {},
   "source": [
    "### 1. Read images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38171e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names = []\n",
    "\n",
    "for i in range(1,202600):\n",
    "    img_name = str(i)\n",
    "    pad_zero = str(0)*(6-len(img_name))\n",
    "    img_name = pad_zero + img_name + '.png'\n",
    "    img_names.append(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90543fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './input/datalab-lab-14-2/' #'./img_align_celeba_png/'\n",
    "\n",
    "def load_img(img_name):\n",
    "    raw_img = tf.io.read_file(DATA_PATH + img_name)\n",
    "    return raw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21fb06bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() \n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def serialize_example(img):\n",
    "    feature = {\n",
    "        'img': _bytes_feature(img)\n",
    "    }\n",
    "    \n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    \n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d99e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_serialize_example(img):\n",
    "    tf_string = tf.py_function(\n",
    "        serialize_example,\n",
    "        [img],\n",
    "        tf.string)\n",
    "    return tf.reshape(tf_string, ())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6520a22e",
   "metadata": {},
   "source": [
    "### 2. Write input images into tf_record "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "643a9883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-22 21:29:04.513050: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-22 21:29:04.532303: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2592000000 Hz\n"
     ]
    }
   ],
   "source": [
    "num=0\n",
    "## 轉成tfrecord\n",
    "for i in range(0,len(img_names),ITEMS_PER_FILE):\n",
    "    raw_image_data = tf.data.Dataset.from_tensor_slices(img_names[i:i+ITEMS_PER_FILE])\n",
    "    raw_image_data = raw_image_data.map(load_img,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    serialized_features_dataset = raw_image_data.map(tf_serialize_example,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    filename = f'./input/google/train_tfrecord/train_{num:03d}_.tfrecord'\n",
    "    writer = tf.data.experimental.TFRecordWriter(filename)\n",
    "    writer.write(serialized_features_dataset)\n",
    "    num+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c2219e",
   "metadata": {},
   "source": [
    "### 3. resize images to 64 x 64 and normalize them for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45117ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(raw_img):\n",
    "    img = tf.image.decode_png(raw_img, channels=3)\n",
    "    # resize inputs into 64x64!\n",
    "    img = tf.image.resize(img, (IMG_H, IMG_W))\n",
    "    img = tf.cast(img,tf.float32)\n",
    "    # normalization\n",
    "    img = img / 255.\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4673a253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_list = []\n",
    "for i in range(102):\n",
    "    filename_list.append(f'./input/google/train_tfrecord/train_{i:03d}_.tfrecord') #(f'./train_tfrecord/train_{i:03d}_.tfrecord')\n",
    "raw_dataset_train = tf.data.TFRecordDataset(filename_list)\n",
    "raw_dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "782f0b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    'img': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    parsed = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    return parsed['img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "290774c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_dataset_train = raw_dataset_train.map(_parse_function)\n",
    "dsTrain = parsed_dataset_train.map(processing)\n",
    "dsTrain = dsTrain.shuffle(BUFFER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7234c2f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# number_of_img = 0\n",
    "# for img in dsTrain:\n",
    "#     if number_of_img == 2:\n",
    "#         break\n",
    "#     plt.imshow(img.numpy())\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()\n",
    "#     number_of_img+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f62d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsTrain = dsTrain.batch(BATCH_SIZE,drop_remainder=True)\n",
    "dsTrain = dsTrain.prefetch(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee60d649",
   "metadata": {},
   "source": [
    "### 4. Imporve WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5c49ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' same with lab14-2 '''\n",
    "def GAN(img_shape, z_dim):\n",
    "    # x-shape\n",
    "    xh, xw, xc = img_shape\n",
    "    # z-shape\n",
    "    zh = xh // 4\n",
    "    zw = xw // 4\n",
    "        \n",
    "    # return Generator and Discriminator\n",
    "    return keras.Sequential([ # Generator\n",
    "        keras.layers.Dense(units  =  1024, input_shape = (z_dim,)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Dense(units  =  zh * zw << 8), # zh * zw * 256\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Reshape(target_shape = (zh, zw, 256)),\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters = 32,\n",
    "            kernel_size = 5,\n",
    "            strides = 2,\n",
    "            padding = \"SAME\"\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Conv2DTranspose(\n",
    "            filters = xc,\n",
    "            kernel_size = 5,\n",
    "            strides = 2,\n",
    "            padding = \"SAME\",\n",
    "            activation = keras.activations.sigmoid\n",
    "        ),\n",
    "    ]), keras.Sequential([ # Discriminator\n",
    "        keras.layers.Conv2D(\n",
    "            filters = 32,\n",
    "            kernel_size = 5,\n",
    "            strides = (2, 2),\n",
    "            padding = \"SAME\",\n",
    "            input_shape = img_shape,\n",
    "        ),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        keras.layers.Conv2D(\n",
    "            filters = 128,\n",
    "            kernel_size = 5,\n",
    "            strides = (2, 2),\n",
    "            padding = \"SAME\"\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(units  =  1024),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        keras.layers.Dense(units  =  1),\n",
    "    ])\n",
    "\n",
    "s = tf.random.normal([SAMPLE_NUM, Z_DIM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8283025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import Image, display\n",
    "# display(Image('14-2_GAN_files/IWGAN algorithm.jpg', height = 600, width=1000, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bda47e4",
   "metadata": {},
   "source": [
    "#### set beta_1 = 0, beta_2 = 0.9, lambda = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "042fde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPROVED_WG, IMPROVED_WD = GAN(IMG_SHAPE, Z_DIM)\n",
    "\n",
    "## 用Adam，而不是RMSprop\n",
    "optimizer_g = keras.optimizers.Adam(learning_rate=IMPROVED_W_LR,beta_1=0.,beta_2=0.9)\n",
    "optimizer_d = keras.optimizers.Adam(learning_rate=IMPROVED_W_LR,beta_1=0.,beta_2=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c13b87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def WGTrain(c1):\n",
    "    # 先random選embedding z\n",
    "    z = tf.random.normal(BZ)\n",
    "    with tf.GradientTape() as tpg:\n",
    "        with tf.GradientTape() as tp_gradientpenalty:\n",
    "            # line 5\n",
    "            x_bar = IMPROVED_WG(z, training = True)\n",
    "            # line 6: random choose epsilon from 0~1, x: grong truth image\n",
    "            epsilon = tf.random.uniform([BATCH_SIZE,1,1,1])\n",
    "            x = c1\n",
    "            x_hat = epsilon * x + (1. - epsilon) * x_bar\n",
    "\n",
    "            # line 7: send x, x_bar, x_hat into\n",
    "            # first term: D_w(x_bar)\n",
    "            z0 = IMPROVED_WD(x_bar, training = True)\n",
    "            # second term\n",
    "            z1 = IMPROVED_WD(x, training = True)\n",
    "            # third term\n",
    "            penalty = IMPROVED_WD(x_hat, training = True)\n",
    "            gradient_penalty = tp_gradientpenalty.gradient(penalty,x_hat)\n",
    "            ## L2 norm\n",
    "            gradient_penalty = tf.sqrt(tf.reduce_sum(tf.math.square(gradient_penalty),axis=[1,2,3]))\n",
    "            ## lambda = 10\n",
    "            loss = z0 - z1 + 10. * tf.math.square((gradient_penalty - 1.))\n",
    "            ld = tf.reduce_mean(loss)\n",
    "            lg = - tf.reduce_mean(z0)\n",
    "\n",
    "    gradient_g = tpg.gradient(lg, IMPROVED_WG.trainable_variables)\n",
    "\n",
    "    optimizer_g.apply_gradients(zip(gradient_g, IMPROVED_WG.trainable_variables))\n",
    "    \n",
    "    return lg, ld\n",
    "\n",
    "@tf.function\n",
    "def WDTrain(c1):\n",
    "    z = tf.random.normal(BZ)\n",
    "    with tf.GradientTape() as tpd:\n",
    "        with tf.GradientTape() as tp_gradientpenalty:\n",
    "            x_bar = IMPROVED_WG(z, training = True)\n",
    "\n",
    "            epsilon = tf.random.uniform([BATCH_SIZE,1,1,1])\n",
    "            x = c1\n",
    "            x_hat = epsilon * x + (1. - epsilon) * x_bar\n",
    "\n",
    "            z1 = IMPROVED_WD(x, training = True)\n",
    "            z0 = IMPROVED_WD(x_bar, training = True)\n",
    "            penalty = IMPROVED_WD(x_hat, training = True)\n",
    "            gradient_penalty = tp_gradientpenalty.gradient(penalty,x_hat)\n",
    "            gradient_penalty = tf.sqrt(tf.reduce_sum(tf.math.square(gradient_penalty),axis=[1,2,3]))\n",
    "            loss = z0 - z1 + 10. * tf.math.square((gradient_penalty - 1.))\n",
    "            ld = tf.reduce_mean(loss)\n",
    "            lg = - tf.reduce_mean(z0)\n",
    "\n",
    "    gradient_d = tpd.gradient(ld, IMPROVED_WD.trainable_variables)\n",
    "\n",
    "    optimizer_d.apply_gradients(zip(gradient_d, IMPROVED_WD.trainable_variables))\n",
    "    \n",
    "    return lg, ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51e15a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "WTrain = (\n",
    "    WDTrain,\n",
    "    WDTrain,\n",
    "    WDTrain,\n",
    "    WDTrain,\n",
    "    WDTrain,\n",
    "    WGTrain\n",
    ")\n",
    "\n",
    "WCritic = len(WTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5524895",
   "metadata": {},
   "source": [
    "#### check point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4240c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "ckpt = tf.train.Checkpoint(IMPROVED_WG = IMPROVED_WG,\n",
    "                           IMPROVED_WD = IMPROVED_WD,\n",
    "                           optimizer_g = optimizer_g,\n",
    "                           optimizer_d = optimizer_d)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75a8a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322b8731",
   "metadata": {},
   "source": [
    "### Error: GPU hanged randomly on some epochs\n",
    "\n",
    "https://stackoverflow.com/questions/47272869/tensorflow-stops-training-and-hanged-on-gpu-randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314926a0",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9193d4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                   | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f534bbc1ec7d4a1fb9cfa44613fab707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-22 21:29:55.217487: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-22 21:29:56.188071: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-22 21:29:56.188123: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2021-12-22 21:29:56.197804: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-22 21:29:57.092356: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8100\n",
      "2021-12-22 21:29:58.280712: E tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-12-22 21:29:58.280741: W tensorflow/stream_executor/gpu/asm_compiler.cc:56] Couldn't invoke ptxas --version\n",
      "2021-12-22 21:29:58.284653: E tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-12-22 21:29:58.284744: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "  0%|▏                                        | 1/256 [01:26<6:07:13, 86.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f46ad8a0194850a46591e0725ab2d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▎                                        | 2/256 [02:46<5:50:11, 82.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4aa6f229dee4e5ca2735a5e19d3e5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▍                                        | 3/256 [04:06<5:43:39, 81.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93fa82aad434e98aee00fa390896fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▋                                        | 4/256 [05:26<5:39:42, 80.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00fe4a1c9b294711afb0970ac6f897ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▊                                        | 5/256 [06:46<5:36:42, 80.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5d27e35f164102bbc800b5592e1510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▉                                        | 6/256 [08:06<5:34:34, 80.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57d424f957646c890424e32d6ff8bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█                                        | 7/256 [09:26<5:32:45, 80.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08119302164d4c0bb0f0ed55eab8c0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█▎                                       | 8/256 [10:46<5:31:15, 80.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13768b63f7642c983b4c4fe8af69cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▍                                       | 9/256 [12:06<5:29:46, 80.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd8432899414d789ff2ddc2644f174a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▌                                      | 10/256 [13:26<5:28:11, 80.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6706c2fcb9443d085028e9bf2cac697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▋                                      | 11/256 [14:46<5:26:39, 80.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18511e537a8420c93fead734ed9a5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|█▉                                      | 12/256 [16:05<5:25:06, 79.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bc1276244b4469ac634c02c8139ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|██                                      | 13/256 [17:25<5:23:52, 79.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aca8167ffa9433d9ab8619972b807b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|██▏                                     | 14/256 [18:45<5:22:34, 79.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14329e401b0e4213a86b53e9a7068f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▎                                     | 15/256 [20:05<5:21:19, 80.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85893043772e4a84b2173ab01de9b23c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▌                                     | 16/256 [21:26<5:20:06, 80.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a55c46e5b5471d8055417044d8ac0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' same with lab14-2 '''\n",
    "wlg = [None] * IMPROVED_W_EPOCH #record loss of g for each epoch\n",
    "wld = [None] * IMPROVED_W_EPOCH #record loss of d for each epoch\n",
    "wsp = [None] * IMPROVED_W_EPOCH #record sample images for each epoch\n",
    "\n",
    "rsTrain = float(BATCH_SIZE) / float(len(img_names))\n",
    "ctr = 0\n",
    "for ep in tqdm(range(IMPROVED_W_EPOCH)):\n",
    "    print(\"Epoch: \" + str(ep+1), end='\\r')\n",
    "    lgt = 0.0\n",
    "    ldt = 0.0\n",
    "    #for idx, c1 in enumerate(dsTrain):\n",
    "    for idx, c1 in tqdm_notebook(enumerate(dsTrain)):\n",
    "        lg, ld = WTrain[ctr](c1)\n",
    "        ctr += 1\n",
    "        lgt += lg.numpy()\n",
    "        ldt += ld.numpy()\n",
    "        if ctr == WCritic : ctr = 0\n",
    "    wlg[ep] = lgt * rsTrain\n",
    "    wld[ep] = ldt * rsTrain\n",
    "    with open('./wlg.txt','a') as f:\n",
    "        f.write(str(lgt * rsTrain) + '\\n')\n",
    "    f.close()\n",
    "    with open('./wld.txt','a') as f:\n",
    "        f.write(str(ldt * rsTrain) + '\\n')\n",
    "    f.close()\n",
    "    \n",
    "    out = IMPROVED_WG(s, training = False)\n",
    "    img = utPuzzle(\n",
    "        (out * 255.0).numpy().astype(np.uint8),\n",
    "        SAMPLE_COL,\n",
    "        SAMPLE_ROW,\n",
    "        \"./output/google/assignment_imgs/w_%04d.png\" % ep\n",
    "    )\n",
    "    wsp[ep] = img\n",
    "    if (ep+1) % 32 == 0: \n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Epoch %d\" % (ep+1))\n",
    "        plt.show()\n",
    "    if (ep+1) % 32 == 0: \n",
    "        ckpt_manager.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b21b37",
   "metadata": {},
   "source": [
    "### 5. GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba5566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "\n",
    "def load_generated_img(path):\n",
    "    image = load_img(path)\n",
    "    data = img_to_array(image).astype(np.uint8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c239e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gan_gen = load_generated_img('./output/google/assignment_imgs/w_0023.png')\n",
    "print(type(img_gan_gen))\n",
    "plt.imshow(img_gan_gen)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4264179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "utMakeGif(np.array(wsp), \"./output/google/imgs/wgan.gif\", duration = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf6dd53",
   "metadata": {},
   "source": [
    "### 6. Draw loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180fee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "wld = []\n",
    "wlg = []\n",
    "with open('./wld.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "for line in lines:\n",
    "    wld.append(float(line.strip('\\n')))\n",
    "    \n",
    "with open('./wlg.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "for line in lines:\n",
    "    wlg.append(float(line.strip('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ecdff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(IMPROVED_W_EPOCH), wld, color = \"blue\", label = \"Discriminator Loss\")\n",
    "plt.plot(range(IMPROVED_W_EPOCH), wlg, color = \"red\", label = \"Generator Loss\")\n",
    "plt.legend(loc = \"lower left\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"WGAN Training Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a24709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d574c73e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
