{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0bfcf30",
   "metadata": {},
   "source": [
    "### 110062539 chKoogoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77401213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT_SHAPE = (224, 224, 3)\n",
    "INPUT_SHAPE = (32, 32, 3)\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "PATIENCE = 99 # 如果過多少個EPOCHS沒改善就停止訓練\n",
    "CATGORICAL = 10\n",
    "LR = 0.001\n",
    "LR_FACTOR = 0.5 # new_lr = lr * factor.\n",
    "LR_PATIENCE = 8 # umber of epochs with no improvement after which learning rate will be reduced\n",
    "MODEL_NAME = 'cifar10_Densenet121_current'\n",
    "MODEL_PATH = MODEL_NAME + '.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "915d1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "import re\n",
    "import PIL\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython import display\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.layers import BatchNormalization, Input, Conv2D, MaxPool2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1915d2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Metal device set to: Apple M1\n",
      " Physical GPUs, 1 Logical GPUs\n",
      "Virtual devices cannot be modified after being initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-17 05:04:51.242198: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-17 05:04:51.242591: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the first GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        # set memory limit\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit = 1024)])\n",
    "\n",
    "       \n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5cf023",
   "metadata": {},
   "source": [
    "## Start Try5: Data augmentation:\n",
    "\n",
    "https://albumentations.ai/docs/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.FancyPCA\n",
    "\n",
    "https://hackmd.io/@allen108108/SyCsOIkxB\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "\n",
    "https://keras.io/zh/preprocessing/image/\n",
    "\n",
    "http://www.tisv.cn/14/\n",
    "\n",
    "- 單純flip, rotate沒什麼用，像是pixelwise的operation效果顯著（試驗第一個連結的所有function）\n",
    "\n",
    "- 之後把有用的function全部放在一起訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b1ce0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('./datalab-cup4-unlearnable-datasets-cifar-10/x_train_cifar10_unlearn.npy')\n",
    "y_train = np.load('./datalab-cup4-unlearnable-datasets-cifar-10/y_train_cifar10.npy')\n",
    "x_val = np.load('./datalab-cup4-unlearnable-datasets-cifar-10/x_val_cifar10.npy')\n",
    "y_val = np.load('./datalab-cup4-unlearnable-datasets-cifar-10/y_val_cifar10.npy')\n",
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_val = np.argmax(y_val, axis=1)\n",
    "\n",
    "# ohe labels\n",
    "y_train = tf.one_hot(y_train, 10)\n",
    "y_val = tf.one_hot(y_val, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d29b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath=MODEL_PATH, \n",
    "                             monitor='val_acc',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='auto', \n",
    "                             save_weights_only = True)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                   factor=LR_FACTOR, \n",
    "                                   patience=LR_PATIENCE, \n",
    "                                   verbose=1, \n",
    "                                   mode='auto', \n",
    "                                   min_delta=1.25e-4)\n",
    "early = EarlyStopping(monitor='val_acc', \n",
    "                      mode=\"auto\", \n",
    "                      patience=PATIENCE)\n",
    "\n",
    "callbacks_list = [checkpoint, reduceLROnPlat, early]\n",
    "#callbacks_list = [checkpoint, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c4aeb3",
   "metadata": {},
   "source": [
    "## Model: Densenet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6269199f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar10_Densenet121_current\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet121 (Functional)    (None, 10)                7047754   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,047,754\n",
      "Trainable params: 6,964,106\n",
      "Non-trainable params: 83,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "''' try2: Densenet121 '''\n",
    "model = Sequential([\n",
    "#    data_augmentation,\n",
    "    tf.keras.applications.DenseNet121(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    pooling=max,\n",
    "    classes=10\n",
    "),\n",
    "#     layers.Conv2D(2048, (1, 1), activation=\"relu\"),\n",
    "#     layers.Dropout(0.25),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dropout(0.5),\n",
    "#     layers.Dense(10, activation='softmax'),\n",
    "],\n",
    "    name=MODEL_NAME\n",
    ")\n",
    "model.build((None, INPUT_SHAPE[0], INPUT_SHAPE[1], INPUT_SHAPE[2]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfdf3767",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.losses.CategoricalCrossentropy(from_logits=False) ##\n",
    "optimizer = tf.optimizers.Adam(learning_rate=LR)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc0dcaf",
   "metadata": {},
   "source": [
    "## Transformer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26d78ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b945b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' define types of transformer of images '''\n",
    "\n",
    "transformer_try = A.Compose([   \n",
    "#    A.ChannelDropout (channel_drop_range=(1, 1), fill_value=0, always_apply=False, p=1)\n",
    "#    A.Downscale (scale_min=0.1, scale_max=0.9, interpolation=cv2.INTER_NEAREST, always_apply=False, p=1),\n",
    "#    A.Emboss (alpha=(0.2, 0.5), strength=(0.2, 0.7), always_apply=False, p=1),\n",
    "#    A.ColorJitter (brightness=0.1, contrast=0.2, saturation=0.3, hue=0.2, always_apply=False, p=1)\n",
    "#    A.Posterize (num_bits=4, always_apply=False, p=1) #不能用\n",
    "#    A.RandomBrightnessContrast (brightness_limit=0.1, contrast_limit=0.2, brightness_by_max=True, always_apply=False, p=1)\n",
    "#    A.Equalize (mode='cv', by_channels=True, mask=None, mask_params=(), always_apply=False, p=1) #不能用\n",
    "#    A.ChannelShuffle(p=1.0)\n",
    "#    A.GridDistortion (num_steps=3, interpolation=cv2.INTER_NEAREST, border_mode=4, value=None, mask_value=None, always_apply=False, p=1)\n",
    "#    A.ISONoise (color_shift=(0.01, 0.05), intensity=(0.1, 0.5), always_apply=False, p=1.0) #不能用\n",
    "#    A.HorizontalFlip(p=1.0)\n",
    "#    A.RGBShift (r_shift_limit=(-40./255, 40./255), g_shift_limit=(-40./255, 40./255), b_shift_limit=(-40./255, 40./255), always_apply=False, p=1.0)\n",
    "#    A.ToGray(p=1.0),\n",
    "#    A.Sharpen (alpha=(0.3, 0.5), lightness=(0.8, 1.0), always_apply=False, p=1.0)\n",
    "#    A.ToSepia (always_apply=False, p=1.0)\n",
    "    A.Superpixels (p_replace=0.1, n_segments=100, max_size=32, interpolation=1, always_apply=False, p=1.0)\n",
    "    \n",
    "    \n",
    "],  p=1)\n",
    "\n",
    "\n",
    "transformer1 = A.Compose([   \n",
    "    A.HueSaturationValue (hue_shift_limit=(-40./255, -40./255), sat_shift_limit=(-60./255, -60./255), val_shift_limit=(-40./255, -40./255), always_apply=False, p=1)\n",
    "],  p=1)\n",
    "\n",
    "transformer7 = A.Compose([   \n",
    "    A.ChannelShuffle(p=1.0)\n",
    "],  p=1)\n",
    "\n",
    "transformer11 = A.Compose([   \n",
    "    A.ToGray(p=1.0)\n",
    "],  p=1)\n",
    "\n",
    "transformer12 = A.Compose([   \n",
    "    A.ToSepia (always_apply=False, p=1.0)\n",
    "],  p=1)\n",
    "\n",
    "transformer5 = A.Compose([   \n",
    "    A.ColorJitter (brightness=0.1, contrast=0.2, saturation=0.3, hue=0.2, always_apply=False, p=1)\n",
    "],  p=1)\n",
    "\n",
    "\n",
    "\n",
    "transformer = A.Compose([   \n",
    "    #A.ChannelDropout (channel_drop_range=(1, 1), fill_value=0, always_apply=False, p=1),\n",
    "    #A.JpegCompression (quality_lower=99, quality_upper=100, always_apply=False, p=1),\n",
    "    A.HueSaturationValue (hue_shift_limit=(-40./255, -40./255), sat_shift_limit=(-60./255, -60./255), val_shift_limit=(-40./255, -40./255), always_apply=False, p=1),\n",
    "#    A.FancyPCA (alpha=0.1, always_apply=False, p=0.5)\n",
    "],  p=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transformer_a = A.Compose([   \n",
    "    #A.ChannelDropout (channel_drop_range=(1, 1), fill_value=0, always_apply=False, p=1),\n",
    "    #A.JpegCompression (quality_lower=99, quality_upper=100, always_apply=False, p=1),\n",
    "    A.HueSaturationValue (hue_shift_limit=(-40./255, -40./255), sat_shift_limit=(-60./255, -60./255), val_shift_limit=(-40./255, -40./255), always_apply=False, p=1),\n",
    "#    A.FancyPCA (alpha=0.1, always_apply=False, p=0.5)\n",
    "],  p=1)\n",
    "\n",
    "transformer_b = A.Compose([   \n",
    "    #A.HorizontalFlip(p=1),\n",
    "#    A.GaussianBlur (blur_limit=(3, 5), sigma_limit=0, always_apply=False, p=1)\n",
    "    A.Affine(p=1),\n",
    "    A.GaussNoise(var_limit=(1.0/255., 10.0/255.), mean=np.mean(x_train[0], axis=(0, 1, 2)), p=1),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.2, brightness_by_max=True, always_apply=False, p=1)\n",
    "    #A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.2, brightness_by_max=True, always_apply=False, p=1)\n",
    "],  p=1)\n",
    "\n",
    "transformer_c = A.Compose([   \n",
    "    A.HorizontalFlip(p=1),\n",
    "    A.GaussNoise(var_limit=(1.0/255., 10.0/255.), mean=np.mean(x_train, axis=(0, 1, 2)), p=1),\n",
    "#    A.MotionBlur(blur_limit=17, p=1)\n",
    "#    A.RGBShift(p=1),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.2, brightness_by_max=True, always_apply=False, p=1)\n",
    "],  p=1)\n",
    "\n",
    "\n",
    "\n",
    "image_size_aug = 36\n",
    "image_size = 32\n",
    "pad_size = int((image_size_aug-image_size)/2)\n",
    "\n",
    "transformer4 = A.Compose([   \n",
    "    #A.ChannelShuffle(p=0.5),\n",
    "    #RandomContrast (limit=0.5, always_apply=False, p=1),\n",
    "    #A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.2, brightness_by_max=True, always_apply=False, p=1),\n",
    "    #A.HorizontalFlip(p=1),\n",
    "    #A.Sharpen (alpha=(0.2, 0.5), lightness=(0.5, 1.0), always_apply=False, p=1)\n",
    "    A.CropAndPad (px=pad_size, percent=None, pad_mode=0, pad_cval=0, pad_cval_mask=0, \n",
    "                keep_size=True, sample_independently=True, interpolation=cv2.INTER_AREA, always_apply=False, p=1.0),\n",
    "    A.CropAndPad (px=-pad_size, percent=None, pad_mode=0, pad_cval=0, pad_cval_mask=0, \n",
    "                keep_size=True, sample_independently=True, interpolation=cv2.INTER_AREA, always_apply=False, p=1.0)\n",
    "],  p=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adfa4ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tf_dl/lib/python3.9/site-packages/albumentations/augmentations/functional.py:1753: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2dde59f40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot transformer_try\n",
    "plt.imshow(transformer_try(image = x_train[0])['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c3a5157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformed_ds_try(img_ds):\n",
    "    num = len(img_ds)\n",
    "    transform_img_ds = []\n",
    "    \n",
    "    for i in range(num):\n",
    "        img_dic = transformer_try(image = img_ds[i])\n",
    "        transform_img_ds.append(img_dic['image'])\n",
    "        \n",
    "    return np.array(transform_img_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e8df0b",
   "metadata": {},
   "source": [
    "## Create transformed training data & Concatenate those data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d30f76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformed_ds(img_ds, transformer):\n",
    "    num = len(img_ds)\n",
    "    transform_img_ds = []\n",
    "    \n",
    "    for i in range(num):\n",
    "        img_dic = transformer(image = img_ds[i])\n",
    "        transform_img_ds.append(img_dic['image'])\n",
    "        \n",
    "    return np.array(transform_img_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eb21eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transformed_data(x_train, y_train, transformer_list, num_data_apply_list):\n",
    "    x_trans_list = []\n",
    "    y_trans_list = []\n",
    "    \n",
    "    for i in range(len(transformer_list)):\n",
    "        x_trans_list.append(transformed_ds(x_train, transformer_list[i])[ : num_data_apply_list[i]])\n",
    "        y_trans_list.append(y_train[ : num_data_apply_list[i]])\n",
    "        \n",
    "#     for transformer in transformer_list:\n",
    "#         x_trans.append(transformed_ds(x_train, transformer))\n",
    "#         y_trans = np.concatenate((y_train , y_train))\n",
    "    \n",
    "    return np.array(np.concatenate(x_trans_list)), np.array(np.concatenate(y_trans_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d684f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_list = [transformer1, transformer7, transformer7, transformer11, transformer12, transformer5]\n",
    "num_data_apply_list = [len(x_train), len(x_train), len(x_train)//2, len(x_train), len(x_train), len(x_train)//2]\n",
    "\n",
    "\n",
    "x_train_trans, y_train_trans = create_transformed_data(x_train, y_train, transformer_list, num_data_apply_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e8792c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_trans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56a7ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformed_ds1(img_ds):\n",
    "    num = len(img_ds)\n",
    "    transform_img_ds = []\n",
    "    \n",
    "    for i in range(num):\n",
    "        img_dic = transformer1(image = img_ds[i])\n",
    "        transform_img_ds.append(img_dic['image'])\n",
    "        \n",
    "    return np.array(transform_img_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e215ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(transformed_ds1(x_train).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b3e71f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02ea3c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check the result:\n",
    "\n",
    "# x_train_trans4 = transformed_ds4(x_train)\n",
    "# x_train_trans3 = transformed_ds3(x_train)\n",
    "# #print(type(x_train_trans))\n",
    "# print(x_train_trans4.shape)\n",
    "# print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b05b59f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try\n",
    "\n",
    "# x_train_trans_try = transformed_ds_try(x_train)\n",
    "# x_train_trans = x_train_trans_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea74e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_trans = np.concatenate((x_train_trans4 , x_train3))\n",
    "# y_train = np.concatenate((y_train , y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75082d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "119b4fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25e84c12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar10_Densenet121_current.hdf5\n"
     ]
    }
   ],
   "source": [
    "print(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3310bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('ChannelShuffle_data.npy', 'wb') as f:\n",
    "#     np.save(f, x_train_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcc85ce",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7fb50a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-17 05:05:47.137121: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-17 05:05:49.893018: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 318/3125 [==>...........................] - ETA: 7:00 - loss: 1.9311 - acc: 0.3056"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=False,  \n",
    "                                             samplewise_center=False, \n",
    "                                             featurewise_std_normalization=False, \n",
    "                                             samplewise_std_normalization=False, \n",
    "                                             zca_whitening=False, ## val只有0.1\n",
    "                                             zca_epsilon=1e-06, \n",
    "                                             rotation_range=0.0, \n",
    "                                             width_shift_range=0.0, ## 0.2\n",
    "                                             height_shift_range=0.0, ## 0.1\n",
    "                                             brightness_range=None, ## 不要用，很爛\n",
    "                                             shear_range=0.0, \n",
    "                                             zoom_range=0.0, \n",
    "                                             channel_shift_range=0.0, \n",
    "                                             fill_mode='nearest', \n",
    "                                             cval=0.0, \n",
    "                                             horizontal_flip=False, \n",
    "                                             vertical_flip=False, ## 不要用，非常糟\n",
    "                                             rescale=None, \n",
    "                                             preprocessing_function=None, \n",
    "                                             data_format=None, \n",
    "                                             validation_split=0.0, \n",
    "                                             dtype=None)\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=0,\n",
    "#     width_shift_range=0.0,\n",
    "#     height_shift_range=0.0)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(x_train_trans, augment=True, rounds=2, seed=None)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "show_augmented_result_dir = './ImageDataGenerator_result'\n",
    "\n",
    "history = model.fit(datagen.flow(x_train_trans, y_train_trans, batch_size=BATCH_SIZE, shuffle=True), \n",
    "                              steps_per_epoch=len(x_train_trans)/BATCH_SIZE, epochs=EPOCHS,\n",
    "                              validation_data=(x_val, y_val),validation_steps=len(x_val)/BATCH_SIZE,\n",
    "                              callbacks=callbacks_list)\n",
    "\n",
    "''' baseline of x_train: 0.5/0.27[1] ~ 0.94/0.33[4] '''\n",
    "'''\n",
    "0.（不能用，因為value是float）FancyPCA (alpha=0.1, always_apply=False, p=0.5): X\n",
    "\n",
    "1. (效果超好！)A.HueSaturationValue (hue_shift_limit=(-40./255, -40./255), sat_shift_limit=(-60./255, -60./255), \n",
    "val_shift_limit=(-40./255, -40./255), always_apply=False, p=1)\n",
    ": 0.41/0.15[1] -> 0.86/0.60[7] -> 0.99/0.66[31]\n",
    "\n",
    "2. (還行)A.ChannelDropout (channel_drop_range=(1, 1), fill_value=0, always_apply=False, p=1)\n",
    ": 0.28/0.29[1] -> 0.85/0.38[7] -> 0.95/0.40[10]\n",
    "\n",
    "3. (bad)A.Downscale (scale_min=0.1, scale_max=0.1, interpolation=cv2.INTER_NEAREST, always_apply=False, p=1)\n",
    ": 0.47/0.24[1] -> 0.94/0.18[4]\n",
    "\n",
    "4. (bad)A.Emboss (alpha=(0.2, 0.5), strength=(0.2, 0.7), always_apply=False, p=1)\n",
    ": 0.49/0.23 -> 0.95/0.25[4]\n",
    "\n",
    "5. (還不錯)A.ColorJitter (brightness=0.1, contrast=0.2, saturation=0.3, hue=0.2, always_apply=False, p=1)\n",
    ": 0.41/0.27[1] -> 0.89/0.46[6]\n",
    "\n",
    "6. (bad)A.RandomBrightnessContrast (brightness_limit=0.1, contrast_limit=0.2, brightness_by_max=True, always_apply=False, p=1)\n",
    ": 0.49/0.26[1] -> 0.93/0.26[4]\n",
    "\n",
    "7. (超棒！)A.ChannelShuffle(p=1.0)\n",
    ": 0.38/0.24[1] -> 0.84/0.59[8] -> 1.0/0.72[50?]\n",
    "(有把training data存下來了('channelShuffle_data.npy')，因為怕是random channelShuffle剛好有不錯的結果)(QQ被我自己洗掉了)\n",
    "\n",
    "8.（普通）A.GridDistortion (num_steps=5, distort_limit=0.3, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=1)\n",
    ": 0.44/0.25[1] -> 0.92/0.37[6] -> 0.95/0.32[10]\n",
    "\n",
    "9. (沒用)HorizontalFlip(p=0.1)\n",
    ": 0.50/0.27[1] -> 0.92/0.29[3]\n",
    "實驗證明，flip在這個task根本沒有幫助\n",
    "\n",
    "10.（普通）A.RGBShift (r_shift_limit=(-40./255, 40./255), g_shift_limit=(-40./255, 40./255), b_shift_limit=(-40./255, 40./255), always_apply=False, p=1.0)\n",
    ": 0.9/0.37[6]\n",
    "跟shift的value有關\n",
    "\n",
    "11. (不錯呦！)A.ToGray(p=1.0)\n",
    ": 0.39/0.29[1] -> 0.86/0.55[8]\n",
    "\n",
    "12. (不錯呦！)A.ToSepia (always_apply=False, p=1.0)\n",
    ": 0.39/0.18[1] -> 0.79/0.52[6] -> 0.96/0.57[11]\n",
    "train epochs要多點, lr小點，太大會overshoot\n",
    "\n",
    "13. (bad)A.Superpixels (p_replace=0.1, n_segments=100, max_size=32, interpolation=1, always_apply=False, p=1.0)\n",
    ": 0.53/0.21[1] -> 0.97/0.29[9]\n",
    "\n",
    "# combined result:\n",
    "\n",
    "((1, 7, 7, 11, 12), (5)), data量(1: 1: 0.5: 1: 1: 0.5)\n",
    ": \n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74108e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('./output_training_plot/densenet121_try5_current', dpi='figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea84790",
   "metadata": {},
   "source": [
    "## Testing data output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0109291",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9c5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('./datalab-cup4-unlearnable-datasets-cifar-10/x_test_cifar10.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736498c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.argmax(model.predict(x_test, batch_size=BATCH_SIZE, verbose=1), axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223360d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_csv = [i for i in range(len(y_test))]\n",
    "df = pd.DataFrame(list(zip(id_csv,y_test)), columns = ['id','label'])\n",
    "df.to_csv('./output_csv/cifar10_try5_densenet121_current.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b4447b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4722148d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec0d95b5",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tf_dl)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
