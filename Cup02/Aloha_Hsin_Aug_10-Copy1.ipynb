{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(input_file):\n",
    "    img_container = [[] for i in range(20)]\n",
    "    oversample_data = []\n",
    "\n",
    "    for line in input_file:\n",
    "        line = line.strip()\n",
    "        oversample_data.append(line)\n",
    "        \n",
    "        img_labels = line.split(\" \")[5::5]\n",
    "        img_labels_counter = np.zeros(20)  \n",
    "        for i in img_labels:\n",
    "            img_labels_counter[int(i)] += 1\n",
    "        \n",
    "        # to deal with the problem of large amount of human\n",
    "        if img_labels_counter[14] > 0:\n",
    "            img_container[14].append(line)\n",
    "        else:\n",
    "            img_container[np.argmax(img_labels_counter)].append(line)\n",
    "\n",
    "\n",
    "    imgNum_of_class = [len(img) for img in img_container]\n",
    "    threshold = max(imgNum_of_class) // 6\n",
    "    \n",
    "    sampled_data = []\n",
    "    for i in range(20):\n",
    "        if imgNum_of_class[i] < threshold :\n",
    "            sampled_data.extend(random.choices(img_container[i], k = threshold - imgNum_of_class[i]))\n",
    "\n",
    "    oversample_data.extend(sampled_data)\n",
    "    \n",
    "    with open('oversample_training_data.txt', 'w') as f:\n",
    "        for item in oversample_data:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "            \n",
    "##################################################\n",
    "\n",
    "    oversample_file = open('oversample_training_data.txt', 'r')\n",
    "    \n",
    "    img_container = [[] for i in range(20)]\n",
    "    \n",
    "    for line in oversample_file:\n",
    "        line = line.strip()\n",
    "        \n",
    "        img_labels = line.split(\" \")[5::5]\n",
    "        img_labels_counter = np.zeros(20)  \n",
    "        for i in img_labels:\n",
    "            img_labels_counter[int(i)] += 1\n",
    "        \n",
    "        img_container[np.argmax(img_labels_counter)].append(line)\n",
    "\n",
    "    imgNum_of_class = [len(img) for img in img_container]\n",
    "    \n",
    "    aug_probability = (np.max(imgNum_of_class) - imgNum_of_class) / imgNum_of_class / 10\n",
    "    return aug_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug('./pascal_voc_training_data.txt', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOLO = yolo(training=True)\n",
    "#YOLO.build(input_shape=(None, IMAGE_SIZE, IMAGE_SIZE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "print(img_inputs)\n",
    "\n",
    "base_model = keras.applications.InceptionResNetV2(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n",
    "# # base_model = keras.applications.ResNet152(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "x = base_model(img_inputs,  training=False)\n",
    "x = base_model(img_inputs)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = conv_leaky_relu(x, 1024, 3, 2)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(4096, kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))(x)\n",
    "x = layers.LeakyReLU(0.1)(x)\n",
    "outputs = layers.Dense(1470, kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))(x)\n",
    "\n",
    "YOLO = keras.Model(inputs=img_inputs, outputs=outputs, name=\"YOLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"yolo_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_resnet_v2 (Functio (None, None, None, 1536)  54336736  \n",
      "_________________________________________________________________\n",
      "conv_leaky_relu_4 (conv_leak multiple                  14159872  \n",
      "_________________________________________________________________\n",
      "conv_leaky_relu_5 (conv_leak multiple                  9441280   \n",
      "_________________________________________________________________\n",
      "conv_leaky_relu_6 (conv_leak multiple                  9441280   \n",
      "_________________________________________________________________\n",
      "conv_leaky_relu_7 (conv_leak multiple                  9441280   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  150994944 \n",
      "_________________________________________________________________\n",
      "batch_normalization_416 (Bat multiple                  16384     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  8388608   \n",
      "_________________________________________________________________\n",
      "batch_normalization_417 (Bat multiple                  8192      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  3012030   \n",
      "=================================================================\n",
      "Total params: 259,240,606\n",
      "Trainable params: 204,883,390\n",
      "Non-trainable params: 54,357,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "YOLO.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base boxes (for loss calculation)\n",
    "base_boxes = np.zeros([CELL_SIZE, CELL_SIZE, 4])\n",
    "\n",
    "# initializtion for each cell\n",
    "for y in range(CELL_SIZE):\n",
    "    for x in range(CELL_SIZE):\n",
    "        base_boxes[y, x, :] = [IMAGE_SIZE / CELL_SIZE * x, \n",
    "                               IMAGE_SIZE / CELL_SIZE * y, 0, 0]\n",
    "\n",
    "base_boxes = np.resize(base_boxes, [CELL_SIZE, CELL_SIZE, 1, 4])\n",
    "base_boxes = np.tile(base_boxes, [1, 1, BOXES_PER_CELL, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = DatasetGenerator().generate()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "\n",
    "train_loss_metric = tf.keras.metrics.Mean(name='loss')\n",
    "\n",
    "ckpt = tf.train.Checkpoint(epoch=tf.Variable(0), net=YOLO)\n",
    "\n",
    "manager = tf.train.CheckpointManager(ckpt, './ckpts/YOLO', max_to_keep=10, checkpoint_name='yolo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image, labels, objects_num):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = YOLO(image)\n",
    "        class_end = CELL_SIZE * CELL_SIZE * NUM_CLASSES\n",
    "        conf_end = class_end + CELL_SIZE * CELL_SIZE * BOXES_PER_CELL\n",
    "        class_probs = tf.reshape(outputs[:, 0:class_end], (-1, 7, 7, 20))\n",
    "        confs = tf.reshape(outputs[:, class_end:conf_end], (-1, 7, 7, 2))\n",
    "        boxes = tf.reshape(outputs[:, conf_end:], (-1, 7, 7, 2*4))\n",
    "        predicts = tf.concat([class_probs, confs, boxes], 3)\n",
    "\n",
    "        loss = yolo_loss(predicts, labels, objects_num)\n",
    "        train_loss_metric(loss)\n",
    "\n",
    "    grads = tape.gradient(loss, YOLO.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, YOLO.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-03 18:26:33.387757, start training.\n",
      "2020-12-03 18:34:22.157202, Epoch 1: loss 11.49\n",
      "Saved checkpoint for epoch 1: ./ckpts/YOLO/yolo-1\n",
      "2020-12-03 18:42:04.518460, Epoch 2: loss 8.07\n",
      "Saved checkpoint for epoch 2: ./ckpts/YOLO/yolo-2\n",
      "2020-12-03 18:49:47.588797, Epoch 3: loss 7.14\n",
      "Saved checkpoint for epoch 3: ./ckpts/YOLO/yolo-3\n",
      "2020-12-03 18:57:30.258279, Epoch 4: loss 6.58\n",
      "Saved checkpoint for epoch 4: ./ckpts/YOLO/yolo-4\n",
      "2020-12-03 19:05:13.122952, Epoch 5: loss 6.12\n",
      "Saved checkpoint for epoch 5: ./ckpts/YOLO/yolo-5\n",
      "2020-12-03 19:12:55.839453, Epoch 6: loss 5.65\n",
      "Saved checkpoint for epoch 6: ./ckpts/YOLO/yolo-6\n",
      "2020-12-03 19:20:39.059359, Epoch 7: loss 5.26\n",
      "Saved checkpoint for epoch 7: ./ckpts/YOLO/yolo-7\n",
      "2020-12-03 19:28:22.140769, Epoch 8: loss 4.94\n",
      "Saved checkpoint for epoch 8: ./ckpts/YOLO/yolo-8\n",
      "2020-12-03 19:36:05.067971, Epoch 9: loss 4.57\n",
      "Saved checkpoint for epoch 9: ./ckpts/YOLO/yolo-9\n",
      "2020-12-03 19:43:48.648398, Epoch 10: loss 4.32\n",
      "Saved checkpoint for epoch 10: ./ckpts/YOLO/yolo-10\n",
      "2020-12-03 19:51:35.439248, Epoch 11: loss 4.01\n",
      "Saved checkpoint for epoch 11: ./ckpts/YOLO/yolo-11\n",
      "2020-12-03 19:59:18.358950, Epoch 12: loss 3.82\n",
      "Saved checkpoint for epoch 12: ./ckpts/YOLO/yolo-12\n",
      "2020-12-03 20:07:01.498290, Epoch 13: loss 3.64\n",
      "Saved checkpoint for epoch 13: ./ckpts/YOLO/yolo-13\n",
      "2020-12-03 20:14:44.398025, Epoch 14: loss 3.53\n",
      "Saved checkpoint for epoch 14: ./ckpts/YOLO/yolo-14\n",
      "2020-12-03 20:22:27.725007, Epoch 15: loss 3.44\n",
      "Saved checkpoint for epoch 15: ./ckpts/YOLO/yolo-15\n",
      "2020-12-03 20:30:10.975560, Epoch 16: loss 3.35\n",
      "Saved checkpoint for epoch 16: ./ckpts/YOLO/yolo-16\n",
      "2020-12-03 20:37:54.322778, Epoch 17: loss 3.24\n",
      "Saved checkpoint for epoch 17: ./ckpts/YOLO/yolo-17\n",
      "2020-12-03 20:45:37.527172, Epoch 18: loss 3.19\n",
      "Saved checkpoint for epoch 18: ./ckpts/YOLO/yolo-18\n",
      "2020-12-03 20:53:21.129133, Epoch 19: loss 3.06\n",
      "Saved checkpoint for epoch 19: ./ckpts/YOLO/yolo-19\n",
      "2020-12-03 21:01:07.754093, Epoch 20: loss 3.04\n",
      "Saved checkpoint for epoch 20: ./ckpts/YOLO/yolo-20\n",
      "2020-12-03 21:08:57.717712, Epoch 21: loss 3.00\n",
      "Saved checkpoint for epoch 21: ./ckpts/YOLO/yolo-21\n",
      "2020-12-03 21:16:44.596361, Epoch 22: loss 2.90\n",
      "Saved checkpoint for epoch 22: ./ckpts/YOLO/yolo-22\n",
      "2020-12-03 21:24:28.160812, Epoch 23: loss 2.83\n",
      "Saved checkpoint for epoch 23: ./ckpts/YOLO/yolo-23\n",
      "2020-12-03 21:32:16.630357, Epoch 24: loss 2.81\n",
      "Saved checkpoint for epoch 24: ./ckpts/YOLO/yolo-24\n",
      "2020-12-03 21:39:59.906255, Epoch 25: loss 2.73\n",
      "Saved checkpoint for epoch 25: ./ckpts/YOLO/yolo-25\n",
      "2020-12-03 21:47:42.695229, Epoch 26: loss 2.69\n",
      "Saved checkpoint for epoch 26: ./ckpts/YOLO/yolo-26\n",
      "2020-12-03 21:55:25.796366, Epoch 27: loss 2.65\n",
      "Saved checkpoint for epoch 27: ./ckpts/YOLO/yolo-27\n",
      "2020-12-03 22:03:08.581285, Epoch 28: loss 2.60\n",
      "Saved checkpoint for epoch 28: ./ckpts/YOLO/yolo-28\n",
      "2020-12-03 22:10:51.871393, Epoch 29: loss 2.56\n",
      "Saved checkpoint for epoch 29: ./ckpts/YOLO/yolo-29\n",
      "2020-12-03 22:18:35.010736, Epoch 30: loss 2.53\n",
      "Saved checkpoint for epoch 30: ./ckpts/YOLO/yolo-30\n",
      "2020-12-03 22:26:18.397059, Epoch 31: loss 2.50\n",
      "Saved checkpoint for epoch 31: ./ckpts/YOLO/yolo-31\n",
      "2020-12-03 22:34:01.519989, Epoch 32: loss 2.46\n",
      "Saved checkpoint for epoch 32: ./ckpts/YOLO/yolo-32\n",
      "2020-12-03 22:41:44.559378, Epoch 33: loss 2.44\n",
      "Saved checkpoint for epoch 33: ./ckpts/YOLO/yolo-33\n",
      "2020-12-03 22:49:27.635117, Epoch 34: loss 2.42\n",
      "Saved checkpoint for epoch 34: ./ckpts/YOLO/yolo-34\n",
      "2020-12-03 22:57:11.223510, Epoch 35: loss 2.40\n",
      "Saved checkpoint for epoch 35: ./ckpts/YOLO/yolo-35\n",
      "2020-12-03 23:04:54.391224, Epoch 36: loss 2.35\n",
      "Saved checkpoint for epoch 36: ./ckpts/YOLO/yolo-36\n",
      "2020-12-03 23:12:42.207843, Epoch 37: loss 2.39\n",
      "Saved checkpoint for epoch 37: ./ckpts/YOLO/yolo-37\n",
      "2020-12-03 23:20:25.448046, Epoch 38: loss 2.34\n",
      "Saved checkpoint for epoch 38: ./ckpts/YOLO/yolo-38\n",
      "2020-12-03 23:28:08.135860, Epoch 39: loss 2.31\n",
      "Saved checkpoint for epoch 39: ./ckpts/YOLO/yolo-39\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-4c0c5a9589b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjects_num\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjects_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}, Epoch {}: loss {:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/s108133505-KBM4lJ_k/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/s108133505-KBM4lJ_k/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/s108133505-KBM4lJ_k/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/s108133505-KBM4lJ_k/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.local/share/virtualenvs/s108133505-KBM4lJ_k/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/share/virtualenvs/s108133505-KBM4lJ_k/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/s108133505-KBM4lJ_k/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"{}, start training.\".format(datetime.now()))\n",
    "for i in range(EPOCHS):\n",
    "    train_loss_metric.reset_states()\n",
    "    ckpt.epoch.assign_add(1)\n",
    "\n",
    "    for idx, (image, labels, objects_num) in enumerate(dataset):\n",
    "        train_step(image, labels, objects_num)\n",
    "\n",
    "    print(\"{}, Epoch {}: loss {:.2f}\".format(datetime.now(), i+1, train_loss_metric.result()))\n",
    "\n",
    "    save_path = manager.save()\n",
    "    print(\"Saved checkpoint for epoch {}: {}\".format(int(ckpt.epoch), save_path))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensemble_boxes import *\n",
    "def process_outputs11111(outputs):\n",
    "    \"\"\"\n",
    "    Process YOLO outputs into bou\n",
    "    \"\"\"\n",
    "\n",
    "    class_end = CELL_SIZE * CELL_SIZE * NUM_CLASSES\n",
    "    conf_end = class_end + CELL_SIZE * CELL_SIZE * BOXES_PER_CELL\n",
    "    class_probs = np.reshape(outputs[:, 0:class_end], (-1, 7, 7, 20))\n",
    "    confs = np.reshape(outputs[:, class_end:conf_end], (-1, 7, 7, 2))\n",
    "    boxes = np.reshape(outputs[:, conf_end:], (-1, 7, 7, 2*4))\n",
    "    predicts = np.concatenate([class_probs, confs, boxes], 3)\n",
    "\n",
    "    p_classes = predicts[0, :, :, 0:20]\n",
    "    C = predicts[0, :, :, 20:22]\n",
    "    coordinate = predicts[0, :, :, 22:]\n",
    "\n",
    "    p_classes = np.reshape(p_classes, (CELL_SIZE, CELL_SIZE, 1, 20))\n",
    "    C = np.reshape(C, (CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 1))\n",
    "    \n",
    "    P = C * p_classes\n",
    "    #P's shape [7, 7, 2, 20]\n",
    "\n",
    "    #choose the bboxes that have confidence non less than 0.5  (sample at most 5 boxes)\n",
    "    threshold = 0.025\n",
    "    sample = 20\n",
    "    _P = P.flatten()\n",
    "    indexes = np.asarray([x for x in np.argsort(_P)[-sample:] if _P[x] >= threshold])\n",
    "#     print(indexes)\n",
    "    # if no box is included(indexes == []), get the most confident one (temporary solution)\n",
    "    if len(indexes) == 0:\n",
    "        indexes = np.asarray([np.argmax(_P)])\n",
    "    idx_cnts = len(indexes)\n",
    "    indexes = np.unravel_index(indexes, P.shape)\n",
    "    max_conf = P[indexes]\n",
    "    xmin = []\n",
    "    ymin = []\n",
    "    xmax = []\n",
    "    ymax = []\n",
    "    class_num = []\n",
    "    \n",
    "    indexes = np.asarray(indexes)\n",
    "    for cnts in range(idx_cnts):\n",
    "        index = indexes[:,cnts]\n",
    "    \n",
    "#     max_conf = np.max(P)\n",
    "#     index = np.argmax(P)\n",
    "\n",
    "#     index = np.unravel_index(index, P.shape)\n",
    "\n",
    "        _class_num = index[3]\n",
    "\n",
    "        coordinate = np.reshape(coordinate, \n",
    "                                (CELL_SIZE, \n",
    "                                 CELL_SIZE,\n",
    "                                 BOXES_PER_CELL, \n",
    "                                 4))\n",
    "\n",
    "        max_coordinate = coordinate[index[0], index[1], index[2], :]\n",
    "\n",
    "        xcenter = max_coordinate[0]\n",
    "        ycenter = max_coordinate[1]\n",
    "        w = max_coordinate[2]\n",
    "        h = max_coordinate[3]\n",
    "\n",
    "        xcenter = (index[1] + xcenter) * (IMAGE_SIZE/float(CELL_SIZE))\n",
    "        ycenter = (index[0] + ycenter) * (IMAGE_SIZE/float(CELL_SIZE))\n",
    "\n",
    "        w = w * IMAGE_SIZE\n",
    "        h = h * IMAGE_SIZE\n",
    "\n",
    "        _xmin = xcenter - w/2.0\n",
    "        _ymin = ycenter - h/2.0\n",
    "\n",
    "        _xmax = _xmin + w\n",
    "        _ymax = _ymin + h\n",
    "        \n",
    "        if(_xmin <= 0):\n",
    "            _xmin = 0.01\n",
    "        if(_ymin <= 0):\n",
    "            _ymin = 0.01\n",
    "        if(_xmax >= IMAGE_SIZE):\n",
    "            _xmax = IMAGE_SIZE-0.01\n",
    "        if(_ymax >= IMAGE_SIZE):\n",
    "            _ymax = IMAGE_SIZE-0.01\n",
    "            \n",
    "        xmin.append(_xmin)\n",
    "        ymin.append(_ymin)\n",
    "        xmax.append(_xmax)\n",
    "        ymax.append(_ymax)\n",
    "        class_num.append(_class_num)\n",
    "    \n",
    "    boxes_list = []\n",
    "    scores_list = max_conf\n",
    "    labels_list = class_num\n",
    "\n",
    "\n",
    "    weights =[3]\n",
    "    iou_thr = 0.5\n",
    "    skip_box_thr = 0.0001\n",
    "    sigma = 0.1\n",
    "\n",
    "    xmin      = np.asarray(xmin)\n",
    "    ymin      = np.asarray(ymin) \n",
    "    xmax      = np.asarray(xmax)\n",
    "    ymax      = np.asarray(ymax)\n",
    "    class_num = np.asarray(class_num)\n",
    "    max_conf  = np.asarray(max_conf)\n",
    "\n",
    "    for i in range(len(xmin)):\n",
    "        box_temp = [ xmin[i]/448., ymin[i]/448., xmax[i]/448., ymax[i]/448.]\n",
    "        boxes_list.append(box_temp)\n",
    "\n",
    "    boxes, scores, labels = nms([boxes_list], [scores_list], [labels_list], weights=None, iou_thr=iou_thr)\n",
    "\n",
    "    xmin_NMS = []\n",
    "    ymin_NMS = []\n",
    "    xmax_NMS = []\n",
    "    ymax_NMS = []\n",
    "    for i in range(len(labels)):\n",
    "#             class_name = classes_name[labels[i]]\n",
    "        xmin_NMS.append(int(boxes[i][0]*448))\n",
    "        ymin_NMS.append(int(boxes[i][1]*448))\n",
    "        xmax_NMS.append(int(boxes[i][2]*448))\n",
    "        ymax_NMS.append(int(boxes[i][3]*448))   \n",
    "\n",
    "    xmin_NMS_big = []\n",
    "    ymin_NMS_big = []\n",
    "    xmax_NMS_big = []\n",
    "    ymax_NMS_big = []\n",
    "    label_NMS_big= []\n",
    "    scores_NMS_big=[]\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        if((xmax_NMS[i]-xmin_NMS[i] >= 10) and (ymax_NMS[i]-ymin_NMS[i] >= 10)):\n",
    "                xmin_NMS_big.append(xmin_NMS[i])\n",
    "                ymin_NMS_big.append(ymin_NMS[i])\n",
    "                xmax_NMS_big.append(xmax_NMS[i])\n",
    "                ymax_NMS_big.append(ymax_NMS[i])\n",
    "                label_NMS_big.append(labels[i])\n",
    "                scores_NMS_big.append(scores[i])\n",
    "    return np.asarray(xmin_NMS_big), np.asarray(ymin_NMS_big), np.asarray(xmax_NMS_big), np.asarray(ymax_NMS_big), np.asarray(label_NMS_big), np.asarray(scores_NMS_big)\n",
    "#     return np.asarray(xmin_NMS), np.asarray(ymin_NMS), np.asarray(xmax_NMS), np.asarray(ymax_NMS), np.asarray(labels), np.asarray(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
